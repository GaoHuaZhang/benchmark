分析 AISBench 的运行视图，包括交互模型和并发模型。先查看相关代码以了解系统运行机制。


[12 tools called]


查看任务执行相关代码，完善对运行视图的理解：


[2 tools called]


基于代码分析，编写 AISBench 运行视图文档：


[1 tool called]


编写 AISBench 运行视图文档，包含交互模型和并发模型：


[1 tool called]


编写 AISBench 运行视图文档：

```markdown:/home/theone/code/dev_branch/benchmark_github/运行视图.md
# AISBench 运行视图设计文档

## 一、交互模型

### 1.1 设计目标

#### 1.1.1 用户友好性
- **命令行接口简洁直观**：提供清晰的命令行参数和帮助信息
- **实时反馈**：在执行过程中提供实时的任务状态和进度信息
- **错误提示明确**：提供详细的错误信息和解决建议

#### 1.1.2 灵活配置
- **多种配置方式**：支持命令行参数、配置文件、环境变量等多种配置方式
- **配置查询**：支持通过 `--search` 参数查询配置文件位置
- **配置验证**：在运行前验证配置的完整性和正确性

#### 1.1.3 可观测性
- **任务监控**：提供实时任务进度看板，显示任务状态、进度、耗时等信息
- **日志管理**：支持调试模式和正常模式，日志可重定向到文件
- **状态持久化**：任务状态通过临时文件持久化，支持断点续测

#### 1.1.4 模式支持
- **多种运行模式**：支持 `all`、`infer`、`eval`、`viz`、`perf`、`perf_viz` 等模式
- **调试模式**：支持 `--debug` 模式，直接打印日志到控制台
- **干运行模式**：支持 `--dry-run` 模式，仅打印命令不执行

### 1.2 设计约束

#### 1.2.1 兼容性约束
- **OpenCompass 兼容**：必须兼容 OpenCompass 的配置体系和命令行接口
- **Python 版本**：仅支持 Python 3.10、3.11、3.12
- **跨平台支持**：支持 Linux、Windows（WSL2）等平台

#### 1.2.2 性能约束
- **启动速度**：CLI 启动时间应尽可能短，延迟导入非核心模块
- **资源占用**：监控进程不应显著影响主任务执行
- **响应性**：任务状态看板刷新间隔可配置，默认 0.3 秒

#### 1.2.3 可用性约束
- **后台运行**：支持在无终端环境下运行（后台模式）
- **中断处理**：支持 Ctrl+C 优雅中断，清理资源
- **断点续测**：支持任务中断后从断点继续执行

### 1.3 交互模型设计

#### 1.3.1 交互层次结构

AISBench 的交互模型采用分层设计，从用户到系统执行共分为五层：

```
┌─────────────────────────────────────────────────────────┐
│  用户层 (User Layer)                                     │
│  - 命令行输入                                            │
│  - 配置文件                                              │
└──────────────────┬──────────────────────────────────────┘
                   │
┌──────────────────▼──────────────────────────────────────┐
│  CLI 层 (CLI Layer)                                       │
│  - main.py: 入口点                                        │
│  - ArgumentParser: 参数解析                               │
│  - TaskManager: 任务管理器                                │
└──────────────────┬──────────────────────────────────────┘
                   │
┌──────────────────▼──────────────────────────────────────┐
│  配置管理层 (Config Management Layer)                     │
│  - ConfigManager: 配置加载和验证                          │
│  - 配置文件查找和匹配                                     │
│  - 配置合并和填充                                         │
└──────────────────┬──────────────────────────────────────┘
                   │
┌──────────────────▼──────────────────────────────────────┐
│  工作流层 (Workflow Layer)                               │
│  - WorkFlowExecutor: 工作流执行器                        │
│  - BaseWorker: 基础工作单元                              │
│    ├─ Infer: 推理工作单元                                │
│    ├─ Eval: 评估工作单元                                 │
│    ├─ AccViz: 精度可视化工作单元                         │
│    └─ PerfViz: 性能可视化工作单元                        │
└──────────────────┬──────────────────────────────────────┘
                   │
┌──────────────────▼──────────────────────────────────────┐
│  执行层 (Execution Layer)                                │
│  - Partitioner: 任务分区器                               │
│  - Runner: 任务运行器                                    │
│  - Task: 具体任务实现                                    │
│  - TasksMonitor: 任务监控器                              │
└─────────────────────────────────────────────────────────┘
```

#### 1.3.2 命令行交互流程

**1. 命令解析阶段**

```python
# main.py
def main():
    task_manager = TaskManager()  # 初始化任务管理器
    task_manager.run()            # 执行任务

# task_manager.py
class TaskManager:
    def __init__(self):
        self.args_parser = ArgumentParser()  # 创建参数解析器
        self.args = self.args_parser.parse_args()  # 解析命令行参数
        self.config_manager = ConfigManager(self.args)  # 创建配置管理器
```

**2. 配置查询模式**（`--search`）

```python
if self.args.search:
    self.config_manager.search_configs_location()  # 查询配置文件位置
    return  # 仅查询，不执行
```

**3. 工作流执行模式**

```python
# 根据运行模式选择工作流
run_mode = self.args.mode  # all, infer, eval, viz, perf, perf_viz
if run_mode == "perf" and self.args.reuse:
    run_mode = "perf_viz"  # 性能模式 + 重用 = 仅可视化

# 构建工作流
self.workflow = [worker_class(self.args) for worker_class in WORK_FLOW.get(run_mode)]

# 加载配置
cfg = self.config_manager.load_config(self.workflow)

# 执行工作流
workflow_executor = WorkFlowExecutor(cfg, self.workflow)
workflow_executor.execute()
```

#### 1.3.3 任务监控交互设计

**1. 监控进程启动**

```python
# LocalRunner.launch()
monitor_p = multiprocessing.Process(
    target=monitor_process,
    args=(task_names, tasks[0]['work_dir'], self.debug, 0.5)
)
monitor_p.start()  # 启动独立监控进程
```

**2. 状态报告机制**

任务状态通过临时文件进行进程间通信：

```python
# TaskStateManager (任务进程)
class TaskStateManager:
    def __init__(self, tmp_path, task_name):
        self.tmp_file = os.path.join(tmp_path, f"tmp_{task_name}.json")

    def update_task_state(self, task_state: dict):
        self.task_state.update(task_state)
        write_status(self.tmp_file, self.task_state)  # 写入状态到临时文件
```

```python
# TasksMonitor (监控进程)
def _refresh_task_state(self):
    statuses = read_and_clear_statuses(self.tmp_file_path, self.tmp_file_name_list)
    # 读取所有任务的临时状态文件并更新监控状态
```

**3. 实时看板显示**

支持两种显示模式：

- **交互式看板**（有终端环境）：
  - 使用 `curses` 库实现全屏交互
  - 支持上下键翻页
  - 支持 'P' 键暂停/恢复刷新
  - 实时显示任务进度、状态、耗时等信息

- **后台模式**（无终端环境）：
  - 使用 `tqdm` 显示进度条
  - 定期输出任务状态到日志

```python
# TasksMonitor.launch_state_board()
if self.is_debug:
    return  # 调试模式不显示看板
if not self.run_in_background:
    curses.wrapper(self._display_task_state)  # 交互式看板
else:
    self._update_tasks_progress()  # 后台模式进度条
```

#### 1.3.4 配置交互设计

**1. 配置文件查找**

```python
# ConfigManager.search_configs_location()
# 支持模糊匹配和精确匹配
# 输出格式化的表格显示配置文件路径
```

**2. 配置加载和验证**

```python
# ConfigManager.load_config()
# 1. 查找并加载模型、数据集、汇总器配置
# 2. 验证配置完整性（CustomConfigChecker）
# 3. 填充默认值和依赖配置
# 4. 合并工作流配置
```

**3. 配置填充**

```python
# 自动填充模型路径（如果数据集需要）
fill_model_path_if_datasets_need(cfg)

# 根据 --num-prompts 限制数据集大小
fill_test_range_use_num_prompts(cfg, self.args.num_prompts)
```

#### 1.3.5 错误处理交互

**1. 参数验证**

```python
# ArgumentParser 中使用验证函数
parser.add_argument('--max-num-workers', type=validate_max_workers)
parser.add_argument('--max-workers-per-gpu', type=validate_max_workers_per_gpu)
```

**2. 配置错误提示**

```python
# CustomConfigChecker
# 检查必需字段，提供明确的错误信息
raise AISBenchConfigError(
    TMAN_CODES.CFG_CONTENT_MISS_REQUIRED_PARAM,
    f"Config file {file_path} does not contain 'models' param!"
)
```

**3. 运行时错误处理**

```python
# 任务执行失败时
if result.returncode != 0:
    self.logger.error(
        RUNNER_CODES.TASK_FAILED,
        f"{task_name} failed with code {result.returncode}, see\n{out_path}"
    )
```

#### 1.3.6 核心交互模型设计

##### 1.3.6.1 配置管理交互模型

**设计抽象**：配置管理交互模型抽象为"请求-解析-查找-加载-验证-合并"的管道式处理流程。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **管道式处理**（最终方案） | 配置处理分为多个阶段，每个阶段独立处理 | 1. 职责清晰，易于维护<br>2. 支持阶段式验证和错误定位<br>3. 易于扩展新阶段 | 1. 需要多次遍历配置<br>2. 中间状态管理复杂 | 复杂配置系统 |
| 一次性加载 | 所有配置一次性加载和验证 | 1. 性能好，只需一次遍历<br>2. 实现简单 | 1. 错误定位困难<br>2. 难以支持增量配置<br>3. 扩展性差 | 简单配置系统 |
| 懒加载 | 按需加载配置项 | 1. 启动速度快<br>2. 内存占用小 | 1. 运行时错误风险高<br>2. 配置依赖关系复杂<br>3. 难以全局验证 | 大型配置系统 |

**顺序图**：配置管理交互流程

```
用户          CLI层          配置管理器        配置文件系统
 │              │                │                  │
 │──命令输入───>│                │                  │
 │              │──参数解析───>│                  │
 │              │                │                  │
 │              │                │──查找配置──────>│
 │              │                │<──返回路径──────│
 │              │                │                  │
 │              │                │──加载配置──────>│
 │              │                │<──配置内容──────│
 │              │                │                  │
 │              │                │──验证配置──────>│
 │              │                │<──验证结果──────│
 │              │                │                  │
 │              │                │──合并配置──────>│
 │              │                │                  │
 │              │<──配置对象─────│                  │
 │              │                │                  │
```

**活动图**：配置加载活动流程

```
[开始]
  │
  ▼
[解析命令行参数]
  │
  ▼
[判断模式]
  │
  ├─查询模式──>[查找配置文件]──>[输出配置路径]──>[结束]
  │
  └─执行模式──>[查找配置文件]
                │
                ▼
              [加载配置]
                │
                ▼
              [验证配置]
                │
                ├─验证失败──>[输出错误信息]──>[结束]
                │
                └─验证成功──>[填充默认值]
                              │
                              ▼
                            [合并工作流配置]
                              │
                              ▼
                            [返回配置对象]
                              │
                              ▼
                            [结束]
```

##### 1.3.6.2 工作流编排交互模型

**设计抽象**：工作流编排抽象为"定义-执行-监控-汇总"的编排模式，支持工作单元的动态组合和顺序执行。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **顺序编排**（最终方案） | 工作单元按顺序执行，每个单元独立完成 | 1. 执行流程清晰<br>2. 错误隔离好<br>3. 易于调试和监控 | 1. 无法并行执行独立单元<br>2. 执行时间较长 | 有依赖关系的任务流 |
| 并行编排 | 独立工作单元并行执行 | 1. 执行效率高<br>2. 资源利用率高 | 1. 依赖关系复杂<br>2. 错误处理困难<br>3. 资源竞争 | 完全独立的任务 |
| 有向无环图（DAG） | 基于依赖关系的图结构编排 | 1. 支持复杂依赖<br>2. 可并行执行独立任务 | 1. 实现复杂<br>2. 依赖解析开销大<br>3. 调试困难 | 复杂依赖关系任务流 |
| 事件驱动 | 基于事件触发工作单元执行 | 1. 解耦性好<br>2. 扩展性强 | 1. 事件管理复杂<br>2. 调试困难<br>3. 时序问题 | 异步事件处理场景 |

**顺序图**：工作流执行交互流程

```
用户          TaskManager      WorkFlowExecutor    BaseWorker      Partitioner      Runner
 │                │                  │                 │                │               │
 │──启动命令───>│                  │                 │                │               │
 │                │──构建工作流───>│                 │                │               │
 │                │                  │                 │                │               │
 │                │                  │──执行工作流───>│                │               │
 │                │                  │                 │                │               │
 │                │                  │                 │──更新配置───>│               │
 │                │                  │                 │<──配置对象────│               │
 │                │                  │                 │                │               │
 │                │                  │                 │──执行工作───>│               │
 │                │                  │                 │                │               │
 │                │                  │                 │                │──分区任务───>│
 │                │                  │                 │                │<──任务列表────│
 │                │                  │                 │                │               │
 │                │                  │                 │                │──启动运行器─>│
 │                │                  │                 │                │               │
 │                │                  │                 │                │               │──执行任务
 │                │                  │                 │                │               │
 │                │                  │                 │<──工作完成────│               │
 │                │                  │                 │                │               │
 │                │                  │<──工作流完成────│                │               │
 │                │                  │                 │                │               │
 │<──执行结果─────│                  │                 │                │               │
```

**状态图**：工作流执行状态转换

```
[初始状态]
  │
  ▼
[构建工作流]
  │
  ▼
[工作流就绪]
  │
  ▼
[执行工作单元1]
  │
  ├─成功──>[执行工作单元2]
  │         │
  │         ├─成功──>[执行工作单元N]
  │         │         │
  │         │         └─成功──>[工作流完成]
  │         │
  │         └─失败──>[工作流失败]
  │
  └─失败──>[工作流失败]
            │
            ▼
          [错误处理]
            │
            ▼
          [结束]
```

##### 1.3.6.3 任务执行与监控交互模型

**设计抽象**：任务执行与监控抽象为"分区-启动-执行-报告-汇总"的分布式执行模式，通过状态同步机制实现实时监控。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **文件状态同步**（最终方案） | 任务进程写入状态文件，监控进程轮询读取 | 1. 实现简单<br>2. 进程解耦<br>3. 支持多进程监控 | 1. 轮询开销<br>2. 状态延迟<br>3. 文件IO开销 | 多进程任务监控 |
| 共享内存 | 使用共享内存直接通信 | 1. 性能好，延迟低<br>2. 实时性强 | 1. 实现复杂<br>2. 需要同步机制<br>3. 内存管理复杂 | 高性能实时监控 |
| 消息队列 | 使用消息队列传递状态 | 1. 解耦性好<br>2. 支持多消费者<br>3. 可靠性高 | 1. 需要额外中间件<br>2. 部署复杂<br>3. 延迟较高 | 分布式系统监控 |
| RPC调用 | 任务进程主动上报状态 | 1. 实时性强<br>2. 双向通信 | 1. 耦合度高<br>2. 网络开销<br>3. 异常处理复杂 | 集中式监控系统 |

**顺序图**：任务执行与监控交互流程

```
主进程        Partitioner      Runner          Task进程        监控进程        状态文件
  │              │               │                │               │              │
  │──分区请求──>│               │                │               │              │
  │              │──返回任务列表─>│                │               │              │
  │              │               │                │               │              │
  │              │               │──启动监控进程──>│               │              │
  │              │               │                │               │              │
  │              │               │──启动任务进程──>│               │              │
  │              │               │                │               │              │
  │              │               │                │──初始化状态──>│              │
  │              │               │                │               │              │──创建文件
  │              │               │                │               │              │
  │              │               │                │──执行任务─────│              │
  │              │               │                │               │              │
  │              │               │                │──更新状态─────│              │
  │              │               │                │               │              │──写入文件
  │              │               │                │               │              │
  │              │               │                │               │──读取状态───>│
  │              │               │                │               │<──状态数据───│
  │              │               │                │               │              │
  │              │               │                │               │──更新看板───│
  │              │               │                │               │              │
  │              │               │                │──任务完成─────│              │
  │              │               │                │               │              │
  │              │               │                │               │──清理文件───>│
  │              │               │                │               │              │
  │              │<──执行结果─────│                │               │              │
```

**活动图**：任务执行与监控活动流程

```
[开始]
  │
  ▼
[任务分区]
  │
  ▼
[启动监控进程]
  │
  ▼
[遍历任务列表]
  │
  ├─有任务──>[获取GPU资源]
  │           │
  │           ├─资源不足──>[等待资源]
  │           │              │
  │           │              └──>[获取GPU资源]
  │           │
  │           └─资源充足──>[启动任务进程]
  │                          │
  │                          ▼
  │                        [任务执行]
  │                          │
  │                          ├─执行中──>[更新状态文件]
  │                          │            │
  │                          │            ▼
  │                          │          [监控读取状态]
  │                          │            │
  │                          │            ▼
  │                          │          [更新看板]
  │                          │            │
  │                          │            └──>[任务执行]
  │                          │
  │                          └─完成──>[释放GPU资源]
  │                                     │
  │                                     └──>[遍历任务列表]
  │
  └─无任务──>[等待所有任务完成]
              │
              ▼
            [汇总结果]
              │
              ▼
            [清理临时文件]
              │
              ▼
            [结束]
```

**状态图**：任务执行状态转换

```
[任务创建]
  │
  ▼
[等待资源]
  │
  ▼
[资源就绪]
  │
  ▼
[任务启动]
  │
  ▼
[执行中]
  │
  ├─正常执行──>[更新进度]
  │              │
  │              └──>[执行中]
  │
  ├─执行完成──>[任务完成]
  │              │
  │              ▼
  │            [释放资源]
  │              │
  │              ▼
  │            [结束]
  │
  └─执行失败──>[任务失败]
                │
                ▼
              [错误处理]
                │
                ▼
              [释放资源]
                │
                ▼
              [结束]
```

##### 1.3.6.4 状态同步交互模型

**设计抽象**：状态同步抽象为"生产者-缓冲区-消费者"的异步通信模式，支持多生产者单消费者的状态聚合。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **文件轮询**（最终方案） | 任务进程写入文件，监控进程轮询读取 | 1. 实现简单<br>2. 进程解耦<br>3. 支持持久化 | 1. 轮询延迟<br>2. 文件IO开销<br>3. 状态可能丢失 | 多进程状态同步 |
| 共享内存+信号量 | 使用共享内存和信号量同步 | 1. 性能好<br>2. 实时性强<br>3. 无文件IO | 1. 实现复杂<br>2. 需要同步机制<br>3. 内存管理复杂 | 高性能实时同步 |
| 消息队列 | 使用消息队列传递状态 | 1. 解耦性好<br>2. 可靠性高<br>3. 支持持久化 | 1. 需要中间件<br>2. 部署复杂<br>3. 延迟较高 | 分布式系统 |
| 事件通知 | 使用事件机制通知状态变化 | 1. 实时性强<br>2. 资源占用小 | 1. 需要事件循环<br>2. 异常处理复杂<br>3. 跨进程复杂 | 单进程或线程间通信 |

**顺序图**：状态同步交互流程

```
任务进程1      任务进程2      任务进程N      状态文件        监控进程
   │              │              │              │               │
   │──写入状态───>│              │              │               │
   │              │              │              │──写入文件─────│
   │              │              │              │               │
   │              │──写入状态───>│              │               │
   │              │              │              │──写入文件─────│
   │              │              │              │               │
   │              │              │──写入状态───>│               │
   │              │              │              │──写入文件─────│
   │              │              │              │               │
   │              │              │              │               │──轮询读取───>│
   │              │              │              │               │<──状态数据───│
   │              │              │              │               │
   │              │              │              │               │──聚合状态───│
   │              │              │              │               │
   │              │              │              │               │──更新看板───│
   │              │              │              │               │
   │              │              │              │               │──清理文件───>│
```

**活动图**：状态同步活动流程

```
[任务进程]
  │
  ▼
[执行任务]
  │
  ▼
[状态变化]
  │
  ▼
[序列化状态]
  │
  ▼
[写入状态文件]
  │
  ▼
[继续执行]
  │
  └──>[执行任务]

[监控进程]
  │
  ▼
[初始化监控]
  │
  ▼
[轮询状态文件]
  │
  ├─有新状态──>[读取状态文件]
  │              │
  │              ▼
  │            [解析状态]
  │              │
  │              ▼
  │            [聚合状态]
  │              │
  │              ▼
  │            [更新看板]
  │              │
  │              ▼
  │            [清理已读状态]
  │              │
  │              └──>[轮询状态文件]
  │
  └─无新状态──>[等待轮询间隔]
                │
                └──>[轮询状态文件]
```

##### 1.3.6.5 交互模型设计总结

AISBench 的交互模型采用**分层管道式架构**，核心特点：

1. **配置管理**：采用管道式处理，支持阶段式验证和错误定位
2. **工作流编排**：采用顺序编排模式，支持工作单元的动态组合
3. **任务执行**：采用分布式执行模式，通过文件状态同步实现监控
4. **状态同步**：采用文件轮询机制，实现多进程状态聚合

这种设计在**简单性**、**可维护性**和**可扩展性**之间取得了良好平衡，适合大规模任务执行和监控场景。

## 二、并发模型

### 2.1 设计目标

#### 2.1.1 高性能
- **高并发支持**：支持 3W+ 并发请求的性能测试
- **资源利用率**：最大化利用 CPU、GPU、网络等资源
- **低延迟**：最小化任务调度和通信开销

#### 2.1.2 可扩展性
- **水平扩展**：支持多进程、多线程扩展
- **动态调整**：根据资源情况动态调整并发度
- **负载均衡**：合理分配任务到不同工作进程

#### 2.1.3 稳定性
- **资源隔离**：进程间资源隔离，避免相互影响
- **故障隔离**：单个任务失败不影响其他任务
- **优雅降级**：资源不足时自动降低并发度

#### 2.1.4 可控性
- **速率控制**：支持请求速率限制（RPS）
- **资源限制**：支持 GPU、内存等资源限制
- **流量模拟**：支持模拟真实业务流量（ramp-up、burstiness）

### 2.2 设计约束

#### 2.2.1 资源约束
- **内存限制**：数据集共享内存占用不超过虚拟内存的 80%
- **GPU 限制**：每个 GPU 最多运行 `max_workers_per_gpu` 个任务
- **进程数限制**：工作进程数不超过 CPU 核心数的 80%

#### 2.2.2 同步约束
- **数据一致性**：多进程共享数据时保证一致性
- **状态同步**：任务状态需要及时同步到监控进程
- **资源竞争**：GPU 资源分配需要加锁保护

#### 2.2.3 性能约束
- **通信开销**：进程间通信应尽可能高效
- **序列化开销**：大数据集序列化/反序列化应优化
- **上下文切换**：减少不必要的进程/线程切换

### 2.3 并发模型设计

#### 2.3.1 多级并发架构

AISBench 采用三级并发架构：

```
┌─────────────────────────────────────────────────────────┐
│  任务级并发 (Task-Level Concurrency)                     │
│  - ThreadPoolExecutor: 管理多个任务                      │
│  - 每个任务独立进程执行                                   │
│  - GPU 资源池管理                                         │
└──────────────────┬──────────────────────────────────────┘
                   │
┌──────────────────▼──────────────────────────────────────┐
│  进程级并发 (Process-Level Concurrency)                   │
│  - multiprocessing.Process: 多个工作进程                  │
│  - 共享内存: 数据集共享                                   │
│  - 消息共享内存: 状态通信                                 │
└──────────────────┬──────────────────────────────────────┘
                   │
┌──────────────────▼──────────────────────────────────────┐
│  异步IO并发 (Async IO Concurrency)                        │
│  - asyncio: 事件循环                                      │
│  - aiohttp: 异步HTTP请求                                  │
│  - Janus队列: 线程-异步桥接                               │
└─────────────────────────────────────────────────────────┘
```

#### 2.3.2 任务级并发设计

**1. 线程池任务调度**

```python
# LocalRunner._run_normal()
with ThreadPoolExecutor(max_workers=self.max_num_workers) as executor:
    status = list(executor.map(submit, tasks, range(len(tasks))))
```

**2. GPU 资源池管理**

```python
# GPU 资源池初始化
gpus = np.zeros(max(all_gpu_ids) + 1, dtype=np.uint)
gpus[all_gpu_ids] = self.max_workers_per_gpu  # 每个GPU的可用槽位

# 任务提交时获取GPU资源
def submit(task, index):
    while True:
        lock.acquire()
        if sum(gpus > 0) >= num_gpus:  # 检查是否有足够GPU
            gpu_ids = np.where(gpus)[0][:num_gpus]  # 分配GPU
            gpus[gpu_ids] -= 1  # 占用GPU槽位
            lock.release()
            break
        lock.release()
        time.sleep(1)  # 等待GPU资源

    res = self._launch(task, gpu_ids, index)  # 执行任务

    with lock:
        gpus[gpu_ids] += 1  # 释放GPU槽位
    return res
```

**3. 任务执行**

每个任务在独立子进程中执行：

```python
# LocalRunner._launch()
cmd = task.get_command(cfg_path=param_file, template=tmpl)
result = subprocess.run(cmd, shell=True, stdout=stdout, stderr=stdout)
```

#### 2.3.3 进程级并发设计

**1. 工作进程创建**

```python
# OpenICLApiInferTask.run()
workers_num = self._get_workers_num()  # 计算工作进程数
workers = []

for i in range(workers_num):
    max_concurrency = min(CONCURRENCY_PER_PROCESS,
                          self.concurrency - i * CONCURRENCY_PER_PROCESS)
    p = Process(
        target=run_single_inferencer,
        args=(model_cfg, inferencer_cfg, shm_name, message_shm_name,
              max_concurrency, indexes, token_bucket, global_index, global_lock)
    )
    workers.append(p)
    p.start()
```

**2. 共享内存数据传递**

```python
# 主进程：创建共享内存
dataset_shm = shared_memory.SharedMemory(create=True, size=dataset_bytes)
# 序列化数据集到共享内存
pickle.dump(data_list, dataset_shm.buf)

# 工作进程：访问共享内存
dataset_shm = shared_memory.SharedMemory(name=shm_name)
data = pickle.loads(dataset_shm.buf)  # 反序列化数据
```

**3. 消息共享内存通信**

```python
# 创建消息共享内存（每个工作进程一个）
message_shm = create_message_share_memory()  # 创建固定大小的共享内存

# 工作进程：更新状态
struct.pack_into("5I", message_buf, offset,
                 post_req, get_req, failed_req, finish_req, finish_case_req)

# 主进程：读取状态
post, recv, fail, finish, case_finish = struct.unpack("5I", message_buf[offset:])
```

**4. 全局索引管理**

```python
# 主进程：创建全局索引和锁
global_index = mp.RawValue('i', 0)  # 共享整数
global_lock = mp.Lock()  # 共享锁

# 工作进程：原子性获取数据索引
with self.global_lock:
    data_index_start = self.global_index.value
    data_index_end = data_index_start + data_fetch_size
    self.global_index.value = data_index_end  # 更新全局索引
```

#### 2.3.4 异步IO并发设计

**1. 事件循环架构**

```python
# BaseApiInferencer.inference_with_shm()
# 创建独立的 asyncio 事件循环
loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)

# 启动生产者线程（同步）
producer_thread = threading.Thread(
    target=self._producer_thread_target,
    args=(dataset_shm, indexes, janus_queue, stop_event)
)
producer_thread.start()

# 启动消费者协程（异步）
loop.run_until_complete(self._worker_loop(token_bucket, janus_queue.async_q))
```

**2. Janus 队列桥接**

Janus 队列用于连接同步线程和异步事件循环：

```python
# 创建 Janus 队列
janus_queue = janus.Queue(maxsize=self.batch_size * 2)

# 生产者线程（同步）：从共享内存读取数据
def _producer_thread_target(...):
    while not stop_event.is_set():
        data = self._get_single_data(dataset_shm, indexes)
        janus_queue.sync_q.put(data)  # 同步队列写入

# 消费者协程（异步）：从队列获取数据并发送请求
async def _worker_loop(...):
    while not stop_event.is_set():
        data = await janus_queue.async_q.get()  # 异步队列读取
        await self.do_request(data, token_bucket, session)
```

**3. 异步请求处理**

```python
# BaseApiInferencer._worker_loop()
# 创建 aiohttp 会话（连接池）
session = aiohttp.ClientSession(
    connector=aiohttp.TCPConnector(limit=num_workers + 1),
    timeout=aiohttp.ClientTimeout(total=get_request_time_out()),
    max_line_size=get_max_chunk_size(),
)

# 并发控制：使用 Semaphore 限制并发数
semaphore = asyncio.Semaphore(num_workers)

async def limited_request_func(data):
    async with semaphore:  # 获取信号量
        await self.do_request(data, token_bucket, session)  # 发送请求

# 创建多个并发任务
tasks = []
for _ in range(num_workers):
    data = await self.wait_get_data(async_queue, stop_event)
    tasks.append(asyncio.create_task(limited_request_func(data)))

await asyncio.gather(*tasks)  # 等待所有任务完成
```

**4. 批量预取优化**

```python
# BaseApiInferencer._get_single_data()
# 批量预取数据，减少锁竞争
data_fetch_size = max(1, int(self.batch_size * DEFAULT_DATA_FETCH_SIZE_FACTOR))

with self.global_lock:
    data_index_start = self.global_index.value
    data_index_end = data_index_start + data_fetch_size
    self.global_index.value = data_index_end

# 预取一批数据到本地缓存
batch_data = []
for data_index in data_indices:
    data = self._read_and_unpickle(share_memory.buf, indexes[data_index])
    batch_data.append(data)

self._data_cache.extend(batch_data[1:])  # 缓存后续数据
return batch_data[0]  # 返回第一个数据
```

#### 2.3.5 速率控制设计

**1. Token Bucket 算法**

```python
# TokenProducer.__init__()
if self.request_rate < FINAL_RPS_MINIMUM_THRESHOLD:
    self.token_bucket = None  # 无速率限制
else:
    self.token_bucket = BoundedSemaphore(request_num + 1)
    # 初始化时清空令牌桶
    for _ in range(request_num + 1):
        self.token_bucket.acquire()

# TokenProducer.produce_token()
# 根据时间间隔释放令牌
while not stop_evt.is_set():
    if interval_index < len(self.interval_lists):
        interval = self.interval_lists[interval_index]
        self.token_bucket.release()  # 释放令牌
        sleep_interval = interval - (current_time - start_time)
        if sleep_interval > 0:
            time.sleep(sleep_interval)
        interval_index += 1

# BaseApiInferencer._worker_loop()
# 请求前获取令牌
if token_bucket:
    acquired = await asyncio.to_thread(token_bucket.acquire, timeout=1)
    if not acquired:
        continue  # 未获取到令牌，跳过本次请求
```

**2. 流量模拟**

支持 ramp-up 和 burstiness 模拟：

```python
# TokenProducer._generate_interval_lists()
for request_index in range(request_num):
    progress = request_index / max(request_num - 1, 1)

    # Ramp-up 策略
    if ramp_up_strategy == "linear":
        current_request_rate = ramp_up_start_rps + (ramp_up_end_rps - ramp_up_start_rps) * progress
    elif ramp_up_strategy == "exponential":
        ratio = ramp_up_end_rps / ramp_up_start_rps
        current_request_rate = ramp_up_start_rps * (ratio ** progress)

    # Burstiness 模拟（Gamma 分布）
    if burstiness == 0:
        interval = 1.0 / current_request_rate  # 固定间隔
    else:
        theta = 1.0 / (current_request_rate * burstiness)
        interval = np.random.gamma(shape=burstiness, scale=theta)  # Gamma 分布

    delay_ts.append(interval)

# 转换为累积延迟
for i in range(1, len(delay_ts)):
    delay_ts[i] += delay_ts[i - 1]
```

#### 2.3.6 压力测试模式

**1. 压力模式特点**

- 持续发送请求直到达到压力时间
- 不限制总请求数
- 支持连接预热

```python
# BaseApiInferencer._worker_loop()
if self.pressure_mode:
    # 预取下一个数据
    next_data_task = asyncio.create_task(self.wait_get_data(async_queue, stop_event))
    await self.do_request(data, token_bucket, session)

    # 持续发送请求直到压力时间
    while time.perf_counter() - start_time < self.pressure_time:
        data = await next_data_task
        if data is None:
            break
        next_data_task = asyncio.create_task(self.wait_get_data(async_queue, stop_event))
        await self.do_request(data, token_bucket, session)
```

**2. 并发度控制**

```python
# 压力模式下，达到最大并发度后停止添加新任务
if self.pressure_mode:
    if len(tasks) >= num_workers:  # 达到最大并发度
        break
    if time.perf_counter() - start_time >= self.pressure_time:  # 达到压力时间
        stop_event.set()
        break
```

#### 2.3.7 资源管理和监控

**1. 内存检查**

```python
# check_virtual_memory_usage()
memory = psutil.virtual_memory()
total_used_after_dataset = memory.used + dataset_bytes
usage_percent = (total_used_after_dataset / memory.total) * 100

if usage_percent > MAX_VIRTUAL_MEMORY_USAGE_PERCENT:
    raise AISBenchRuntimeError(
        TINFER_CODES.VIRTUAL_MEMORY_USAGE_TOO_HIGH,
        f"Virtual memory usage too high: {usage_percent:.2f}%"
    )
```

**2. 进度监控**

```python
# ProgressBar._read_shared_memory_and_update_per_pid()
# 从每个工作进程的共享内存读取状态
for pid, shm in self.per_pid_shms.items():
    raw = bytes(shm.buf[:MESSAGE_SIZE])
    _, post, recv, fail, finish, case_finish = struct.unpack(FMT, raw)
    self.per_pid_stats[pid] = {
        "post": int(post),
        "recv": int(recv),
        "fail": int(fail),
        "finish": int(finish),
        "case_finish": int(case_finish),
    }

# 聚合所有进程的统计信息
self._recalc_aggregate()
```

**3. 速率计算**

```python
# ProgressBar._compute_rates_interval()
# 计算当前时间间隔内的速率
now = time.perf_counter()
dt = now - self._last_snapshot_time
rates = {}
for k in self._keys:
    rates[k] = (self.stats.get(k, 0) - self._last_snapshot_stats.get(k, 0)) / dt
```

#### 2.3.8 并发模型详细设计

##### 2.3.8.1 任务级并发设计

**设计抽象**：任务级并发抽象为"资源池-任务调度-进程隔离"的模式，通过线程池管理任务生命周期，通过资源池管理GPU资源分配。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **线程池+资源池**（最终方案） | 使用ThreadPoolExecutor管理任务，使用资源池管理GPU | 1. 资源利用率高<br>2. 任务隔离好<br>3. 易于控制并发度 | 1. 线程开销<br>2. GIL限制 | 多任务并行执行 |
| 进程池 | 使用ProcessPoolExecutor管理任务 | 1. 真正的并行<br>2. 无GIL限制 | 1. 进程开销大<br>2. 资源管理复杂<br>3. 通信开销大 | CPU密集型任务 |
| 协程池 | 使用asyncio管理任务 | 1. 轻量级<br>2. 高并发 | 1. 不适合阻塞IO<br>2. 资源管理复杂 | IO密集型任务 |
| 单线程顺序执行 | 顺序执行所有任务 | 1. 实现简单<br>2. 资源占用小 | 1. 执行时间长<br>2. 资源利用率低 | 小规模任务 |

**技术决策**：选择线程池+资源池方案，因为：
1. 任务执行在独立子进程中，不受GIL限制
2. GPU资源需要精确控制，资源池模式更适合
3. 线程池开销小，适合任务调度场景

**类图**：任务级并发架构

```
┌─────────────────────┐
│   LocalRunner        │
├─────────────────────┤
│ - max_num_workers    │
│ - max_workers_per_gpu│
│ - debug              │
├─────────────────────┤
│ + launch()           │
│ + _run_normal()      │
│ + _launch()           │
└──────────┬──────────┘
           │
           │ uses
           ▼
┌─────────────────────┐
│  ThreadPoolExecutor │
├─────────────────────┤
│ - max_workers       │
├─────────────────────┤
│ + submit()           │
│ + map()              │
└──────────┬──────────┘
           │
           │ manages
           ▼
┌─────────────────────┐
│   GPUResourcePool    │
├─────────────────────┤
│ - gpus: ndarray      │
│ - lock: Lock         │
├─────────────────────┤
│ + acquire()          │
│ + release()          │
└─────────────────────┘
```

**顺序图**：任务级并发执行流程

```
主进程        ThreadPoolExecutor    GPUResourcePool    Task进程
  │                  │                    │                │
  │──提交任务──────>│                    │                │
  │                  │                    │                │
  │                  │──获取GPU资源──────>│                │
  │                  │                    │                │
  │                  │                    │──检查资源─────│
  │                  │                    │                │
  │                  │                    ├─资源不足──>[等待]
  │                  │                    │                │
  │                  │                    └─资源充足──>[分配GPU]
  │                  │                    │                │
  │                  │                    │<──返回GPU ID───│
  │                  │                    │                │
  │                  │──启动任务进程──────>│                │
  │                  │                    │                │
  │                  │                    │                │──执行任务
  │                  │                    │                │
  │                  │                    │                │──任务完成
  │                  │                    │                │
  │                  │──释放GPU资源──────>│                │
  │                  │                    │                │
  │<──任务结果───────│                    │                │
```

**活动图**：任务级并发活动流程

```
[开始]
  │
  ▼
[初始化GPU资源池]
  │
  ▼
[创建线程池]
  │
  ▼
[遍历任务列表]
  │
  ├─有任务──>[提交任务到线程池]
  │           │
  │           ▼
  │         [等待GPU资源]
  │           │
  │           ├─资源不足──>[阻塞等待]
  │           │              │
  │           │              └──>[等待GPU资源]
  │           │
  │           └─资源充足──>[分配GPU]
  │                          │
  │                          ▼
  │                        [启动任务进程]
  │                          │
  │                          ▼
  │                        [执行任务]
  │                          │
  │                          ├─执行中──>[等待完成]
  │                          │            │
  │                          │            └──>[执行任务]
  │                          │
  │                          └─完成──>[释放GPU]
  │                                     │
  │                                     └──>[遍历任务列表]
  │
  └─无任务──>[等待所有任务完成]
              │
              ▼
            [关闭线程池]
              │
              ▼
            [结束]
```

##### 2.3.8.2 进程级并发设计

**设计抽象**：进程级并发抽象为"主进程-工作进程-共享内存"的模式，通过共享内存实现高效数据传递，通过全局索引实现负载均衡。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **共享内存+多进程**（最终方案） | 使用multiprocessing.Process和shared_memory | 1. 数据传递高效<br>2. 真正的并行<br>3. 内存共享 | 1. 需要序列化<br>2. 同步机制复杂 | 大规模数据处理 |
| 消息队列 | 使用multiprocessing.Queue传递数据 | 1. 解耦性好<br>2. 实现简单 | 1. 序列化开销大<br>2. 内存占用高<br>3. 性能较差 | 小规模数据传递 |
| 管道通信 | 使用multiprocessing.Pipe传递数据 | 1. 双向通信<br>2. 实现简单 | 1. 只能传递小数据<br>2. 性能较差 | 小数据量通信 |
| 单进程多线程 | 使用threading.Thread | 1. 开销小<br>2. 共享内存方便 | 1. GIL限制<br>2. 无法真正并行 | CPU密集型不适合 |

**技术决策**：选择共享内存+多进程方案，因为：
1. 数据集可能很大，共享内存避免多次复制
2. 多进程实现真正的并行，不受GIL限制
3. 通过全局索引实现负载均衡，避免数据倾斜

**类图**：进程级并发架构

```
┌─────────────────────┐
│  OpenICLApiInferTask │
├─────────────────────┤
│ - workers_num       │
│ - concurrency       │
├─────────────────────┤
│ + run()              │
│ + _run_multi_process()│
└──────────┬──────────┘
           │
           │ creates
           ▼
┌─────────────────────┐
│   WorkerProcess     │
├─────────────────────┤
│ - target            │
│ - args              │
├─────────────────────┤
│ + start()            │
│ + join()             │
└──────────┬──────────┘
           │
           │ uses
           ▼
┌─────────────────────┐
│  SharedMemory       │
├─────────────────────┤
│ - name              │
│ - size              │
│ - buf               │
├─────────────────────┤
│ + create()           │
│ + attach()           │
└──────────┬──────────┘
           │
           │ contains
           ▼
┌─────────────────────┐
│  GlobalIndex        │
├─────────────────────┤
│ - value: RawValue    │
│ - lock: Lock         │
├─────────────────────┤
│ + acquire()          │
│ + release()          │
└─────────────────────┘
```

**顺序图**：进程级并发执行流程

```
主进程        工作进程1        工作进程2        工作进程N        共享内存        全局索引
  │              │                │                │                │               │
  │──创建共享内存─>│                │                │                │               │
  │              │                │                │                │──初始化───────│
  │              │                │                │                │               │
  │──序列化数据──>│                │                │                │               │
  │              │                │                │                │──写入数据─────│
  │              │                │                │                │               │
  │──创建全局索引─>│                │                │                │               │
  │              │                │                │                │               │──初始化
  │              │                │                │                │               │
  │──启动工作进程1─>│                │                │                │               │
  │              │                │                │                │               │
  │              │──附加共享内存──>│                │                │               │
  │              │                │                │                │               │
  │──启动工作进程2─>│                │                │                │               │
  │              │                │                │                │               │
  │              │                │──附加共享内存──>│                │               │
  │              │                │                │                │               │
  │──启动工作进程N─>│                │                │                │               │
  │              │                │                │                │               │
  │              │                │                │──附加共享内存──>│               │
  │              │                │                │                │               │
  │              │──获取数据索引──>│                │                │               │
  │              │                │                │                │               │──加锁
  │              │                │                │                │               │──读取索引
  │              │                │                │                │               │──更新索引
  │              │                │                │                │               │──释放锁
  │              │                │                │                │               │
  │              │<──返回索引─────│                │                │                │
  │              │                │                │                │               │
  │              │──读取数据──────>│                │                │                │
  │              │                │                │                │<──返回数据─────│
  │              │                │                │                │               │
  │              │──处理数据──────│                │                │                │
  │              │                │                │                │               │
  │              │                │──获取数据索引──>│                │               │
  │              │                │                │                │               │
  │              │                │                │──获取数据索引──>│               │
  │              │                │                │                │               │
  │              │──工作完成──────│                │                │                │
  │              │                │                │                │               │
  │              │                │──工作完成──────│                │                │
  │              │                │                │                │               │
  │              │                │                │──工作完成──────│                │
  │              │                │                │                │               │
  │──等待所有进程──>│                │                │                │               │
  │              │                │                │                │               │
  │<──所有进程完成─│                │                │                │               │
```

**状态图**：工作进程状态转换

```
[进程创建]
  │
  ▼
[附加共享内存]
  │
  ▼
[初始化Inferencer]
  │
  ▼
[就绪]
  │
  ▼
[获取数据索引]
  │
  ├─有数据──>[读取数据]
  │            │
  │            ▼
  │          [处理数据]
  │            │
  │            ├─处理中──>[更新状态]
  │            │            │
  │            │            └──>[获取数据索引]
  │            │
  │            └─处理完成──>[获取数据索引]
  │
  └─无数据──>[进程完成]
              │
              ▼
            [清理资源]
              │
              ▼
            [结束]
```

##### 2.3.8.3 异步IO并发设计

**设计抽象**：异步IO并发抽象为"生产者-队列-消费者"的模式，通过Janus队列桥接同步线程和异步事件循环，实现高效的IO并发处理。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **Janus队列+asyncio**（最终方案） | 使用Janus队列桥接线程和异步 | 1. 桥接同步异步<br>2. 高并发IO<br>3. 资源利用率高 | 1. 实现复杂<br>2. 调试困难 | 高并发网络IO |
| 纯asyncio | 全部使用异步IO | 1. 性能好<br>2. 资源占用小 | 1. 需要异步库支持<br>2. 共享内存访问困难 | 纯异步场景 |
| 多线程同步IO | 使用threading和requests | 1. 实现简单<br>2. 易于调试 | 1. 线程开销大<br>2. GIL限制<br>3. 并发度受限 | 低并发场景 |
| 协程池 | 使用gevent等协程库 | 1. 高并发<br>2. 兼容同步代码 | 1. 需要monkey patch<br>2. 兼容性问题 | 需要兼容同步代码 |

**技术决策**：选择Janus队列+asyncio方案，因为：
1. 需要从共享内存（同步）读取数据，然后异步发送请求
2. Janus队列完美桥接同步和异步，避免数据复制
3. asyncio+aiohttp提供高并发网络IO能力

**类图**：异步IO并发架构

```
┌─────────────────────┐
│  BaseApiInferencer  │
├─────────────────────┤
│ - batch_size        │
│ - pressure_mode     │
├─────────────────────┤
│ + inference_with_shm()│
│ + _worker_loop()     │
└──────────┬──────────┘
           │
           │ uses
           ▼
┌─────────────────────┐
│    JanusQueue       │
├─────────────────────┤
│ - sync_q            │
│ - async_q           │
├─────────────────────┤
│ + put()              │
│ + get()              │
└──────────┬──────────┘
           │
           │ bridges
           ▼
┌─────────────────────┐      ┌─────────────────────┐
│  ProducerThread     │      │  ConsumerCoroutine   │
├─────────────────────┤      ├─────────────────────┤
│ - target            │      │ - loop              │
├─────────────────────┤      ├─────────────────────┤
│ + run()              │      │ + await get()       │
└─────────────────────┘      │ + await request()   │
                              └─────────────────────┘
```

**顺序图**：异步IO并发执行流程

```
主线程        ProducerThread    JanusQueue      EventLoop      ConsumerCoroutine    aiohttp
  │                │                │                │                │                │
  │──启动生产者线程─>│                │                │                │                │
  │                │                │                │                │                │
  │──创建事件循环──>│                │                │                │                │
  │                │                │                │                │                │
  │──启动消费者协程─>│                │                │                │                │
  │                │                │                │                │                │
  │                │──从共享内存读取─│                │                │                │
  │                │                │                │                │                │
  │                │──写入同步队列──>│                │                │                │
  │                │                │                │                │                │
  │                │                │──数据转换──────>│                │                │
  │                │                │                │                │                │
  │                │                │                │──从异步队列获取─│                │
  │                │                │                │                │                │
  │                │                │                │                │──获取令牌──────│
  │                │                │                │                │                │
  │                │                │                │                │──发送请求──────>│
  │                │                │                │                │                │
  │                │                │                │                │                │──HTTP请求
  │                │                │                │                │                │
  │                │                │                │                │<──响应─────────│
  │                │                │                │                │                │
  │                │                │                │                │──处理响应──────│
  │                │                │                │                │                │
  │                │──继续读取数据──│                │                │                │
  │                │                │                │                │                │
  │                │                │                │──继续获取数据───│                │
  │                │                │                │                │                │
  │                │──写入结束标记──>│                │                │                │
  │                │                │                │                │                │
  │                │                │                │──获取结束标记───│                │
  │                │                │                │                │                │
  │                │                │                │──协程完成──────│                │
  │                │                │                │                │                │
  │──等待线程完成───>│                │                │                │                │
  │                │                │                │                │                │
  │<──所有完成──────│                │                │                │                │
```

**活动图**：异步IO并发活动流程

```
[开始]
  │
  ▼
[创建Janus队列]
  │
  ▼
[创建事件循环]
  │
  ▼
[启动生产者线程]
  │
  ▼
[启动消费者协程]
  │
  ▼
[生产者：从共享内存读取]
  │
  ├─有数据──>[写入同步队列]
  │           │
  │           ▼
  │         [继续读取]
  │           │
  │           └──>[生产者：从共享内存读取]
  │
  └─无数据──>[写入结束标记]
              │
              ▼
            [线程结束]

[消费者：从异步队列获取]
  │
  ├─有数据──>[获取令牌]
  │           │
  │           ├─无令牌──>[等待令牌]
  │           │            │
  │           │            └──>[获取令牌]
  │           │
  │           └─有令牌──>[发送HTTP请求]
  │                        │
  │                        ▼
  │                      [处理响应]
  │                        │
  │                        ▼
  │                      [继续获取]
  │                        │
  │                        └──>[消费者：从异步队列获取]
  │
  └─结束标记──>[协程完成]
                │
                ▼
              [关闭会话]
                │
                ▼
              [结束]
```

##### 2.3.8.4 速率控制设计

**设计抽象**：速率控制抽象为"令牌桶-生产者-消费者"的模式，通过Token Bucket算法实现精确的请求速率控制，支持ramp-up和burstiness模拟。

**备选方案对比**：

| 方案 | 设计思路 | 优点 | 缺点 | 适用场景 |
|------|---------|------|------|---------|
| **Token Bucket**（最终方案） | 使用BoundedSemaphore实现令牌桶 | 1. 精确控制速率<br>2. 支持突发流量<br>3. 实现简单 | 1. 需要独立线程<br>2. 内存占用 | 精确速率控制 |
| 固定延迟 | 每个请求后固定延迟 | 1. 实现简单<br>2. 资源占用小 | 1. 无法处理突发<br>2. 速率不精确 | 简单场景 |
| 滑动窗口 | 使用时间窗口统计请求数 | 1. 平滑控制<br>2. 支持突发 | 1. 实现复杂<br>2. 内存占用大 | 需要平滑控制 |
| 漏桶算法 | 固定速率输出请求 | 1. 平滑输出<br>2. 防止突发 | 1. 不支持突发<br>2. 速率固定 | 需要平滑输出 |

**技术决策**：选择Token Bucket方案，因为：
1. 支持突发流量，更符合真实业务场景
2. 实现相对简单，使用BoundedSemaphore即可
3. 可以精确控制平均速率和峰值速率

**类图**：速率控制架构

```
┌─────────────────────┐
│   TokenProducer     │
├─────────────────────┤
│ - request_rate      │
│ - traffic_cfg       │
│ - token_bucket      │
│ - interval_lists    │
├─────────────────────┤
│ + produce_token()    │
│ + _generate_interval_lists()│
└──────────┬──────────┘
           │
           │ produces
           ▼
┌─────────────────────┐
│  BoundedSemaphore   │
├─────────────────────┤
│ - value             │
│ - maxsize           │
├─────────────────────┤
│ + acquire()          │
│ + release()          │
└──────────┬──────────┘
           │
           │ consumed by
           ▼
┌─────────────────────┐
│  BaseApiInferencer  │
└─────────────────────┘
```

**顺序图**：速率控制执行流程

```
TokenProducer    BoundedSemaphore    WorkerCoroutine
      │                  │                    │
      │──初始化令牌桶────>│                    │
      │                  │                    │
      │──清空令牌桶──────>│                    │
      │                  │                    │
      │──启动生产者线程──│                    │
      │                  │                    │
      │──计算时间间隔────│                    │
      │                  │                    │
      │──释放令牌────────>│                    │
      │                  │                    │
      │                  │                    │──请求令牌───>│
      │                  │                    │                │
      │                  │<──获取令牌──────────│                │
      │                  │                    │                │
      │                  │                    │──发送请求──────│
      │                  │                    │                │
      │──继续释放令牌────>│                    │                │
      │                  │                    │                │
      │                  │                    │──请求令牌───>│
      │                  │                    │                │
      │                  │<──获取令牌──────────│                │
      │                  │                    │                │
      │                  │                    │──发送请求──────│
      │                  │                    │                │
      │──所有令牌释放完成─│                    │                │
      │                  │                    │                │
      │──线程结束────────│                    │                │
```

**状态图**：速率控制状态转换

```
[初始化]
  │
  ▼
[创建令牌桶]
  │
  ▼
[清空令牌桶]
  │
  ▼
[计算时间间隔列表]
  │
  ▼
[生产者就绪]
  │
  ▼
[释放令牌]
  │
  ├─有间隔──>[等待间隔]
  │            │
  │            ▼
  │          [释放令牌]
  │
  └─无间隔──>[生产者完成]
              │
              ▼
            [结束]
```

##### 2.3.8.5 并发模型技术决策总结

**多级并发架构的技术决策**：

1. **任务级并发**：选择线程池+资源池方案
   - **原因**：任务在独立进程中执行，不受GIL限制；GPU资源需要精确控制
   - **权衡**：线程开销 vs 进程开销，选择线程池更轻量

2. **进程级并发**：选择共享内存+多进程方案
   - **原因**：数据集可能很大，共享内存避免多次复制；多进程实现真正并行
   - **权衡**：共享内存同步复杂度 vs 消息队列性能，选择共享内存更高效

3. **异步IO并发**：选择Janus队列+asyncio方案
   - **原因**：需要桥接同步（共享内存）和异步（网络IO）；asyncio提供高并发能力
   - **权衡**：实现复杂度 vs 性能，选择Janus队列平衡两者

4. **速率控制**：选择Token Bucket方案
   - **原因**：支持突发流量，更符合真实场景；实现相对简单
   - **权衡**：精确度 vs 复杂度，选择Token Bucket平衡两者

**整体架构优势**：
- **高性能**：多级并发充分利用CPU、GPU、网络资源
- **可扩展**：支持从单机到分布式的水平扩展
- **可控性**：精确的速率控制和资源管理
- **稳定性**：资源隔离和故障隔离机制

#### 2.3.9 并发可靠性设计

##### 2.3.9.1 异常处理机制

**设计抽象**：异常处理采用"分层捕获-分类处理-错误记录"的模式，在不同并发层次实现相应的异常处理策略。

**异常处理层次**：

1. **请求级异常处理**（BaseAPIModel.generate）
   - **异常类型**：
     - `asyncio.exceptions.CancelledError`：用户取消请求，立即停止重试
     - `json.JSONDecodeError`：响应格式错误，停止重试（无法恢复）
     - `Exception`：其他异常，记录错误信息并继续重试
   - **处理策略**：
     ```python
     retry_count = 0
     for _ in range(self.retry):
         try:
             await self.text_infer(request_body, output)
             break  # 成功则退出重试循环
         except asyncio.exceptions.CancelledError:
             output.success = False
             output.error_info = "Request cancelled by user"
             break  # 用户取消，立即退出
         except json.JSONDecodeError:
             break  # 格式错误，无法恢复，退出
         except Exception as e:
             retry_count += 1
             output.success = False
             output.error_info = f"After {retry_count} retries, request failed: {type(e).__name__}: {str(e)}"
             continue  # 继续重试
     ```

2. **协程级异常处理**（BaseApiInferencer._worker_loop）
   - **异常类型**：
     - `asyncio.exceptions.CancelledError`：键盘中断，优雅关闭
   - **处理策略**：
     ```python
     try:
         await asyncio.gather(*tasks)
     except asyncio.exceptions.CancelledError:
         stop_event.set()
         for t in tasks:
             if not t.done():
                 t.cancel()
         await asyncio.gather(*tasks, return_exceptions=True)
     finally:
         await session.close()  # 确保资源清理
     ```

3. **进程级异常处理**（LocalRunner._run_normal）
   - **异常类型**：
     - `KeyboardInterrupt`：用户中断，等待任务完成
   - **处理策略**：
     ```python
     try:
         status = list(executor.map(submit, tasks, range(len(tasks))))
     except KeyboardInterrupt:
         monitor_p.join()
         self.logger.warning("Main process interrupted by user! Waiting for running tasks to complete...")
         status = list(status) if status is not None else []
     ```

4. **任务级异常处理**（Task执行）
   - **异常类型**：
     - 任务执行失败（returncode != 0）
   - **处理策略**：
     ```python
     if result.returncode != 0:
         self.logger.error(
             RUNNER_CODES.TASK_FAILED,
             f"{task_name} failed with code {result.returncode}, see\n{out_path}"
         )
     ```

**异常处理流程图**：

```
[请求发送]
  │
  ├─成功──>[记录成功]──>[继续]
  │
  ├─CancelledError──>[记录取消]──>[停止]
  │
  ├─JSONDecodeError──>[记录格式错误]──>[停止]
  │
  └─其他异常──>[记录错误]
                 │
                 ├─重试次数未满──>[等待]──>[重试]
                 │                           │
                 │                           └──>[请求发送]
                 │
                 └─重试次数已满──>[记录最终失败]──>[停止]
```

##### 2.3.9.2 重试策略

**设计抽象**：重试策略采用"指数退避-次数限制-类型过滤"的模式，针对不同异常类型采用不同的重试策略。

**重试策略设计**：

1. **请求级重试**（BaseAPIModel）
   - **重试次数**：`retry` 参数控制，默认 2 次，范围 [0, 1000]
   - **重试条件**：
     - 网络错误（连接超时、连接失败等）
     - 服务器错误（5xx 状态码）
     - 临时性错误（可恢复的异常）
   - **不重试条件**：
     - 用户取消（CancelledError）
     - 格式错误（JSONDecodeError）
     - 客户端错误（4xx 状态码，部分）
   - **重试间隔**：当前实现为立即重试，可优化为指数退避

2. **任务级重试**（LocalRunner）
   - **重试策略**：当前不支持自动重试，失败任务需要手动重新运行
   - **断点续测**：支持通过 `--reuse` 参数跳过已完成任务，实现部分重试

3. **进程级重试**（工作进程）
   - **重试策略**：进程失败后不自动重启，由主进程记录失败状态
   - **故障隔离**：单个进程失败不影响其他进程

**重试策略对比表**：

| 层次 | 重试机制 | 重试次数 | 重试间隔 | 适用场景 |
|------|---------|---------|---------|---------|
| 请求级 | 立即重试 | 0-1000（默认2） | 无延迟 | 网络请求失败 |
| 任务级 | 手动重试 | 无限制 | 手动控制 | 任务执行失败 |
| 进程级 | 无自动重试 | 0 | N/A | 进程崩溃 |

**重试策略优化建议**：

1. **指数退避**：请求级重试可引入指数退避，避免对服务器造成压力
   ```python
   import asyncio
   retry_delay = 2 ** retry_count  # 指数退避
   await asyncio.sleep(retry_delay)
   ```

2. **重试队列**：对于失败请求，可加入重试队列，在后台异步重试

3. **熔断机制**：连续失败达到阈值时，暂停重试，避免资源浪费

##### 2.3.9.3 回滚策略

**设计抽象**：回滚策略采用"资源释放-状态清理-数据恢复"的模式，确保异常情况下系统能够恢复到一致状态。

**回滚策略设计**：

1. **资源释放**
   - **GPU资源回滚**：
     ```python
     try:
         res = self._launch(task, gpu_ids, index)
     finally:
         with lock:
             gpus[gpu_ids] += 1  # 确保GPU资源释放
     ```
   - **共享内存清理**：
     ```python
     try:
         # 使用共享内存
         pass
     finally:
         dataset_shm.close()
         dataset_shm.unlink()  # 清理共享内存
     ```
   - **HTTP会话关闭**：
     ```python
     try:
         await asyncio.gather(*tasks)
     finally:
         await session.close()  # 确保会话关闭
     ```

2. **状态清理**
   - **临时文件清理**：
     ```python
     try:
         # 执行任务
         pass
     finally:
         if not self.keep_tmp_file:
             os.remove(param_file)  # 清理临时配置文件
     ```
   - **状态文件清理**：
     ```python
     finally:
         TasksMonitor.rm_tmp_files(tasks[0]['work_dir'])  # 清理状态文件
     ```

3. **数据恢复**
   - **部分结果保存**：任务失败时，已处理的数据结果已保存，可通过 `--reuse` 参数恢复
   - **检查点机制**：定期保存处理进度，支持从检查点恢复

**回滚策略流程图**：

```
[异常发生]
  │
  ▼
[捕获异常]
  │
  ▼
[记录错误信息]
  │
  ▼
[释放资源]
  │
  ├─GPU资源──>[归还GPU槽位]
  │
  ├─共享内存──>[关闭共享内存]
  │
  ├─HTTP会话──>[关闭会话]
  │
  └─临时文件──>[删除临时文件]
  │
  ▼
[清理状态]
  │
  ├─状态文件──>[删除状态文件]
  │
  └─进程状态──>[更新进程状态]
  │
  ▼
[数据恢复]
  │
  ├─部分结果──>[保存已处理数据]
  │
  └─检查点──>[保存处理进度]
  │
  ▼
[回滚完成]
```

#### 2.3.10 并发池参数设计

##### 2.3.10.1 参数体系

**设计抽象**：并发池参数采用"分层配置-动态计算-范围验证"的模式，在不同并发层次配置相应的参数。

**参数层次结构**：

```
并发参数体系
├── 任务级参数
│   ├── max_num_workers: 线程池最大工作线程数
│   └── max_workers_per_gpu: 每个GPU的最大工作线程数
├── 进程级参数
│   ├── WORKERS_NUM: 工作进程数（全局配置）
│   └── CONCURRENCY_PER_PROCESS: 每个进程的最大并发数
└── 异步IO级参数
    ├── batch_size: 批处理大小（模型配置）
    └── MAX_BATCH_SIZE: 最大批处理大小限制
```

##### 2.3.10.2 任务级并发参数

**1. max_num_workers（线程池大小）**

- **定义**：ThreadPoolExecutor 的最大工作线程数
- **默认值**：16
- **取值范围**：[1, +∞)
- **设计考虑**：
  - **CPU核心数**：建议设置为 CPU 核心数的 1-2 倍
  - **任务类型**：IO密集型任务可设置较大值，CPU密集型任务应设置较小值
  - **内存限制**：每个线程占用一定内存，需考虑总内存限制
- **计算公式**：
  ```
  max_num_workers = min(CPU核心数 × 2, 内存限制 / 单线程内存占用)
  ```

**2. max_workers_per_gpu（GPU并发度）**

- **定义**：每个 GPU 同时运行的任务数
- **默认值**：1
- **取值范围**：[1, +∞)
- **设计考虑**：
  - **GPU内存**：每个任务占用 GPU 内存，需确保总占用不超过 GPU 显存
  - **任务类型**：推理任务通常设置为 1，训练任务可设置更大值
  - **性能权衡**：并发度过高可能导致 GPU 利用率下降
- **计算公式**：
  ```
  max_workers_per_gpu = min(GPU显存 / 单任务显存占用, 性能最优值)
  ```

##### 2.3.10.3 进程级并发参数

**1. WORKERS_NUM（工作进程数）**

- **定义**：工作进程的总数
- **默认值**：0（自动计算）
- **取值范围**：[1, CPU核心数 × 0.8]
- **设计考虑**：
  - **自动计算**：当为 0 时，根据 `concurrency` 和 `CONCURRENCY_PER_PROCESS` 自动计算
  - **计算公式**：
    ```python
    if WORKERS_NUM > 0:
        workers_num = min(WORKERS_NUM, MAX_WORKERS_NUM)
    else:
        workers_num = (concurrency - 1) // CONCURRENCY_PER_PROCESS + 1
        workers_num = min(workers_num, MAX_WORKERS_NUM)
    ```
  - **性能考虑**：
    - 进程数过多：上下文切换开销大，性能下降
    - 进程数过少：无法充分利用多核 CPU
    - 建议值：CPU 核心数的 0.5-0.8 倍

**2. CONCURRENCY_PER_PROCESS（单进程并发数）**

- **定义**：每个工作进程的最大并发请求数
- **默认值**：500
- **取值范围**：[1, MAX_BATCH_SIZE]
- **设计考虑**：
  - **内存限制**：每个并发请求占用内存，需考虑进程内存限制
  - **网络限制**：并发数过高可能导致网络拥塞
  - **性能权衡**：并发数过低无法充分利用网络带宽，过高可能导致请求排队
- **计算公式**：
  ```
  CONCURRENCY_PER_PROCESS = min(网络带宽 / 单请求带宽, 进程内存 / 单请求内存, 500)
  ```

##### 2.3.10.4 异步IO级并发参数

**1. batch_size（批处理大小）**

- **定义**：异步IO的批处理大小，控制并发请求数
- **默认值**：1
- **取值范围**：[1, MAX_BATCH_SIZE]
- **设计考虑**：
  - **网络带宽**：批处理大小应匹配网络带宽
  - **服务器能力**：需考虑服务器并发处理能力
  - **延迟要求**：批处理大小过大可能导致延迟增加
- **计算公式**：
  ```
  batch_size = min(网络带宽 / 单请求带宽, 服务器QPS, 延迟要求下的最优值)
  ```

**2. MAX_BATCH_SIZE（最大批处理大小）**

- **定义**：批处理大小的上限
- **默认值**：100000
- **取值范围**：[1, +∞)
- **设计考虑**：
  - **内存限制**：防止内存溢出
  - **系统限制**：考虑操作系统和网络栈的限制
  - **实际需求**：根据实际测试场景设置合理上限

##### 2.3.10.5 参数调优策略

**参数调优流程**：

```
[初始参数]
  │
  ▼
[性能测试]
  │
  ├─性能不足──>[增加并发参数]
  │              │
  │              ├─资源充足──>[继续增加]
  │              │              │
  │              │              └──>[性能测试]
  │              │
  │              └─资源不足──>[优化资源分配]
  │                             │
  │                             └──>[性能测试]
  │
  ├─资源耗尽──>[减少并发参数]
  │              │
  │              └──>[性能测试]
  │
  └─性能满足──>[记录最优参数]
                 │
                 ▼
               [结束]
```

**参数调优建议**：

1. **渐进式调优**：从较小值开始，逐步增加，观察性能变化
2. **资源监控**：监控 CPU、内存、GPU、网络使用率，避免资源耗尽
3. **性能测试**：在不同负载下测试，找到最优参数组合
4. **场景适配**：根据具体测试场景（精度测试 vs 性能测试）调整参数

**参数配置示例**：

```python
# 小规模测试（单机，少量数据）
max_num_workers = 4
max_workers_per_gpu = 1
batch_size = 10
WORKERS_NUM = 2

# 中等规模测试（单机，中等数据量）
max_num_workers = 16
max_workers_per_gpu = 1
batch_size = 100
WORKERS_NUM = 4

# 大规模测试（单机，大量数据）
max_num_workers = 32
max_workers_per_gpu = 2
batch_size = 500
WORKERS_NUM = 8

# 超大规模测试（分布式）
max_num_workers = 64
max_workers_per_gpu = 4
batch_size = 1000
WORKERS_NUM = 16
```

### 2.4 并发模型总结

AISBench 的并发模型采用**多级并发架构**，实现了：

1. **任务级并发**：通过线程池管理多个任务，GPU 资源池确保资源合理分配
2. **进程级并发**：通过多进程实现真正的并行执行，共享内存实现高效数据传递
3. **异步IO并发**：通过 asyncio + aiohttp 实现高并发网络请求，Janus 队列桥接同步和异步
4. **速率控制**：通过 Token Bucket 算法和流量模拟实现精确的请求速率控制
5. **资源管理**：通过内存检查、GPU 资源池、进程数限制等机制确保系统稳定性
6. **可靠性设计**：通过异常处理、重试策略、回滚机制确保系统可靠性
7. **参数优化**：通过分层参数设计和调优策略实现性能优化

这种设计使得 AISBench 能够支持从单机小规模测试到大规模分布式性能测试的各种场景，同时保证系统的可靠性和性能。
```

文档已创建，包含：

1. **交互模型**：
   - 设计目标：用户友好性、灵活配置、可观测性、模式支持
   - 设计约束：兼容性、性能、可用性约束
   - 交互模型设计：分层架构、命令行交互流程、任务监控、配置交互、错误处理

2. **并发模型**：
   - 设计目标：高性能、可扩展性、稳定性、可控性
   - 设计约束：资源、同步、性能约束
   - 并发模型设计：多级并发架构、任务级并发、进程级并发、异步IO并发、速率控制、压力测试、资源管理

文档基于代码分析，涵盖了 AISBench 运行视图的核心设计。