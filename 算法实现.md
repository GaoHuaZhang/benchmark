分析 AISBench 中的算法实现。查看关键算法代码：


[6 tools called]


继续查看其他关键算法实现：


[6 tools called]


继续查看其他关键算法实现：


[4 tools called]


基于代码分析，整理 AISBench 的算法实现文档：

## AISBench 算法实现文档

### 一、设计目标

#### 1.1 核心目标

1. 高效推理
   - 支持高并发异步推理
   - 多进程并行处理
   - 共享内存优化数据传递

2. 灵活评估
   - 支持多种评估指标（accuracy、pass@k、cons@k、avg@n）
   - 支持生成式和困惑度两种推理模式
   - 支持多次独立推理场景

3. 精确性能测量
   - 精确的时间戳记录
   - 多维度性能指标计算
   - 统计分析（平均值、中位数、百分位数）

4. 可扩展性
   - 基于注册表的插件化架构
   - 支持自定义推理器、评估器、检索器
   - 模块化设计，易于扩展

### 二、设计约束

#### 2.1 性能约束

1. 内存约束
   - 大规模数据集需分批处理
   - 共享内存大小限制（检查虚拟内存使用率，阈值80%）
   - 避免内存峰值

2. 并发约束
   - 单进程最大并发：`CONCURRENCY_PER_PROCESS = 500`
   - 批处理大小范围：`[1, MAX_BATCH_SIZE]`，`MAX_BATCH_SIZE = 100000`
   - 支持多进程扩展

3. 时间约束
   - 请求超时控制
   - 流式响应处理
   - 实时状态更新

#### 2.2 功能约束

1. 数据一致性
   - 预测结果与标准答案长度必须一致
   - 多次推理场景下，n次结果必须完整

2. 模式兼容性
   - PPL模式不支持性能测试和流式接口
   - 性能测试仅支持流式接口

### 三、技术选型

#### 3.1 异步并发框架

选型：asyncio + aiohttp
- 理由：
  - 原生异步支持，事件循环高效
  - aiohttp 支持高并发 HTTP 请求
  - 支持流式响应处理
  - 资源占用低

#### 3.2 多进程通信

选型：multiprocessing + shared_memory
- 理由：
  - 共享内存高效，避免序列化开销
  - 支持多进程并行
  - 进程间数据共享

#### 3.3 线程-异步桥接

选型：janus.Queue
- 理由：
  - 线程安全的生产者-消费者队列
  - 支持同步和异步接口
  - 解决阻塞操作与异步事件循环的桥接

#### 3.4 统计计算

选型：NumPy + SciPy
- 理由：
  - 高效的数值计算
  - 丰富的统计函数
  - 支持超几何分布计算（pass@k）

### 四、算法实现

#### 4.1 推理算法（Inferencer）

##### 4.1.1 生成式推理算法（GenInferencer）

设计思路：
- 基于 Few-shot Learning 的生成式推理
- 支持零样本和少样本场景

算法流程：
```
1. 检索阶段（Retriever）：
   - 从训练集中检索示例（Zero-shot返回空列表）
   - 生成In-Context Examples (ICE)

2. 提示词生成阶段：
   - 使用ICE模板生成示例
   - 使用Prompt模板生成完整提示词
   - 解析模板，适配模型格式

3. 推理阶段：
   - 异步并发发送请求
   - 流式/非流式响应处理
   - 记录时间戳（性能模式）

4. 结果处理阶段：
   - 提取预测内容
   - 保存中间结果（支持断点续测）
   - 更新状态计数器
```

关键技术：
- 异步并发：使用 `asyncio.Semaphore` 控制并发数
- 批处理：支持批量数据预取和处理
- 流式处理：支持流式响应，实时记录时间戳

##### 4.1.2 困惑度推理算法（PPLInferencer）

设计思路：
- 基于困惑度的选择题评估
- 计算每个选项的困惑度，选择最低的作为答案

算法流程：
```
1. 标签获取：
   - 从Retriever获取所有候选标签
   - 或使用配置中指定的标签列表

2. 提示词生成（每个选项）：
   for each label in labels:
       prompt = generate_label_prompt(idx, ice, label)
       token_num = get_token_len(prompt)
       存储prompt和token_num

3. 困惑度计算：
   for each label:
       发送请求计算该选项的困惑度
       记录log-likelihood

4. 答案选择：
   prediction = label with minimum perplexity
```

特点：
- 不支持性能测试模式
- 不支持流式接口
- 需要为每个选项单独计算

##### 4.1.3 异步并发推理算法

设计思路：
- 生产者-消费者模式
- 线程负责数据读取，异步协程负责请求发送

算法流程：
```
1. 数据准备阶段：
   - 序列化数据集到共享内存
   - 创建索引映射表
   - 初始化全局索引和锁

2. 生产者线程：
   - 从共享内存批量读取数据
   - 使用全局锁保护索引更新
   - 将数据放入janus队列

3. 消费者协程（Worker Loop）：
   - 从异步队列获取数据
   - 使用Semaphore控制并发
   - 发送异步请求
   - 处理响应并更新状态

4. 状态监控线程：
   - 定期读取状态计数器
   - 写入共享内存供主进程监控
```

关键技术：
- 批量预取：每次预取 `batch_size * 0.1` 的数据，减少锁竞争
- 双缓冲：使用缓存队列减少等待时间
- 背压控制：队列满时自然阻塞，实现背压

#### 4.2 检索算法（Retriever）

##### 4.2.1 零样本检索（ZeroRetriever）

算法实现：
```python
def retrieve(self) -> List[List]:
    # 为每个测试样本返回空列表
    return [[] for _ in range(len(self.test_ds))]
```

特点：
- 时间复杂度：O(n)，n为测试集大小
- 空间复杂度：O(n)
- 适用于零样本场景

##### 4.2.2 固定K样本检索（FixKRetriever）

算法实现：
```python
def retrieve(self):
    # 为每个测试样本返回相同的K个示例索引
    rtr_idx_list = []
    for _ in range(len(self.test_ds)):
        rtr_idx_list.append(self.fix_id_list)
    return rtr_idx_list
```

特点：
- 时间复杂度：O(n)
- 空间复杂度：O(k)，k为固定示例数
- 适用于Few-shot场景，所有样本使用相同的示例

##### 4.2.3 提示词生成算法

ICE生成算法：
```python
def generate_ice(self, idx_list: List[int]) -> str:
    generated_ice_list = []
    for idx in idx_list:
        ice_item = ice_template.generate_ice_item(
            index_ds[idx],
            index_ds[idx][output_column]
        )
        generated_ice_list.append(ice_item)

    # 使用分隔符连接
    ice = ice_separator.join(generated_ice_list) + ice_eos_token
    return ice
```

完整提示词生成：
```python
def generate_prompt_for_generate_task(idx, ice, gen_field_replace_token=""):
    # 使用模板生成完整提示词
    # gen_field_replace_token用于防止答案泄露
    prompt = prompt_template.generate_item(
        test_ds[idx],
        output_field=output_column,
        output_field_replace_token=gen_field_replace_token,
        ice_field_replace_token=ice
    )
    return prompt
```

#### 4.3 评估算法（Evaluator）

##### 4.3.1 Pass@k 计算算法

算法实现：
```python
def compute_pass_at_k(n: int, c: int, k: int) -> float:
    """
    n: 总样本数（n次独立推理）
    c: 正确样本数
    k: Top k值
    """
    if n - c < k:
        return 1.0
    # 使用超几何分布计算
    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))
```

数学原理：
- 基于超几何分布
- 计算在n次独立推理中，至少k次正确的概率
- 公式：`1 - ∏(1 - k/(n-c+i))`，i从1到c

##### 4.3.2 Cons@k 计算算法

算法实现：
```python
# 在reduce方法中
if c > k / 2:
    detail[f'cons@{k}'] = 1.0  # 多数投票正确
else:
    detail[f'cons@{k}'] = 0.0  # 多数投票错误
```

特点：
- Cons@k：Top k次推理中，多数投票是否正确的指标
- 如果正确次数 > k/2，则cons@k = 1，否则为0

##### 4.3.3 Avg@n 计算算法

算法实现：
```python
# 平均准确率
detail[f'avg@{n}'] = c / total_samples
# c: 正确次数
# total_samples: 总推理次数（n次）
```

特点：
- 计算n次独立推理的平均准确率
- 简单直观的指标

##### 4.3.4 评估聚合算法（reduce）

算法流程：
```
1. 全局样本准确率：
   - 计算所有样本的avg@n平均值
   - 计算所有样本的pass@k平均值
   - 计算所有样本的cons@k平均值

2. 分类别统计：
   - 按subdivision分组
   - 计算每个类别的avg@n、pass@k、cons@k

3. 保留原始数据：
   - 提取非核心字段
   - 数值字段计算平均值
   - 非数值字段保留原始值
```

#### 4.4 性能计算算法（Calculator）

##### 4.4.1 延迟指标计算

E2EL（End-to-End Latency）：
```python
E2EL = end_time - start_time
# 从请求发送到响应完成的完整延迟
```

TTFT（Time To First Token）：
```python
TTFT = first_token_time - start_time
# 从请求发送到收到第一个token的时间
```

TPOT（Time Per Output Token）：
```python
TPOT = (end_time - first_token_time) / output_tokens
# 每个输出token的平均生成时间
```

ITL（Inter-Token Latency）：
```python
ITL = [time_points[i+1] - time_points[i] for i in range(len(time_points)-1)]
# Token之间的延迟列表
```

##### 4.4.2 吞吐量计算算法

QPS（Queries Per Second）：
```python
QPS = total_requests / benchmark_duration
```

TPUT（Throughput）：
```python
# 输入Token吞吐量
InputTokenThroughput = total_input_tokens / benchmark_duration

# 输出Token吞吐量
OutputTokenThroughput = total_output_tokens / benchmark_duration

# 总Token吞吐量
TotalTokenThroughput = (total_input_tokens + total_output_tokens) / benchmark_duration
```

##### 4.4.3 统计指标计算算法

算法实现：
```python
def _calculate_statistics(self, data: list) -> dict:
    arr = np.array(data)
    stats = {}

    if "Average" in stats_list:
        stats["Average"] = arr.mean()
    if "Min" in stats_list:
        stats["Min"] = arr.min()
    if "Max" in stats_list:
        stats["Max"] = arr.max()
    if "Median" in stats_list:
        stats["Median"] = np.percentile(arr, 50)
    if "P75" in stats_list:
        stats["P75"] = np.percentile(arr, 75)
    if "P90" in stats_list:
        stats["P90"] = np.percentile(arr, 90)
    if "P99" in stats_list:
        stats["P99"] = np.percentile(arr, 99)

    return stats
```

特点：
- 使用NumPy高效计算
- 支持自定义百分位数（P1-P99）
- 自动单位转换（秒转毫秒）

#### 4.5 任务分区算法（Partitioner）

##### 4.5.1 简单分区算法（NaivePartitioner）

算法流程：
```
1. 遍历模型-数据集组合：
   for each combination:
       for each model:
           for each dataset:
               检查输出文件是否存在
               如果存在且可重用，跳过
               否则加入chunks列表

2. 按n分组：
   for i in range(0, len(chunks), n):
       创建任务：models + datasets[i:i+n]
       添加到任务列表

3. 返回任务列表
```

特点：
- 时间复杂度：O(m * d)，m为模型数，d为数据集数
- 支持断点续测：检查输出文件是否存在
- 支持任务合并：n > 1时，多个数据集合并为一个任务

#### 4.6 并发控制算法

##### 4.6.1 Token Bucket 限流算法

设计思路：
- 使用 `BoundedSemaphore` 实现令牌桶
- 控制请求发送速率

实现：
```python
token_bucket = BoundedSemaphore(max_tokens)
# 发送请求前获取令牌
await token_bucket.acquire()
# 请求完成后释放令牌
token_bucket.release()
```

##### 4.6.2 并发分配算法

算法实现：
```python
def _deliver_concurrency_for_workers(self):
    workers_num = max(1, int(round(self._get_workers_num())))
    total_concurrency = int(self.concurrency)

    # 平均分配，余数分配给前r个进程
    q, r = divmod(total_concurrency, workers_num)
    per_worker_concurrency = [q + 1] * r + [q] * (workers_num - r)

    return per_worker_concurrency
```

特点：
- 尽可能均匀分配并发数
- 余数分配给前r个进程

#### 4.7 共享内存管理算法

##### 4.7.1 数据集序列化算法

算法流程：
```
1. 序列化数据：
   pickled_dataset = [pickle.dumps(data) for data in data_list]

2. 计算总大小：
   dataset_bytes = sum(len(b) for b in pickled_dataset)

3. 检查内存：
   if virtual_memory_usage > 80%:
       raise Exception("Memory usage too high")

4. 创建共享内存：
   dataset_shm = SharedMemory(create=True, size=dataset_bytes)

5. 写入数据并创建索引：
   offset = 0
   for data, length in zip(pickled_dataset, lengths):
       buf[offset:offset+length] = data
       indexes[index] = (index, offset, length)
       offset += length
```

##### 4.7.2 数据读取算法

算法流程：
```
1. 批量预取：
   data_fetch_size = max(1, int(batch_size * 0.1))

2. 原子获取索引：
   with global_lock:
       start = global_index.value
       end = start + data_fetch_size
       global_index.value = end

3. 批量读取：
   for index in range(start, end):
       offset, length = indexes[index]
       data = pickle.loads(buf[offset:offset+length])
       cache.append(data)

4. 返回第一个，其余缓存
```

### 五、算法优化策略

#### 5.1 性能优化

1. 批量处理
   - 批量预取数据，减少锁竞争
   - 批量保存结果，减少IO次数

2. 异步并发
   - 使用asyncio实现高并发
   - 连接池复用，减少连接开销

3. 内存优化
   - 共享内存避免数据复制
   - 分批处理避免内存峰值

#### 5.2 可靠性优化

1. 断点续测
   - 检查已完成的数据
   - 跳过已完成的样本

2. 错误处理
   - 请求重试机制
   - 失败样本记录
   - 状态监控和恢复

#### 5.3 可扩展性优化

1. 插件化架构
   - 基于注册表的组件发现
   - 接口抽象，易于扩展

2. 配置驱动
   - 通过配置文件组合算法
   - 支持自定义算法实现

以上是 AISBench 中主要算法的实现分析，涵盖设计目标、约束、技术选型和具体算法实现。