分析 AISBench 的数据模型设计。查看关键代码文件：


[5 tools called]


查看更多数据模型相关信息：


[5 tools called]


基于代码分析，整理 AISBench 的数据模型设计文档：

## AISBench 数据模型设计文档

### 一、设计目标

#### 1.1 核心目标

1. 兼容性
   - 兼容 OpenCompass 的数据格式和配置体系
   - 支持 HuggingFace Datasets 生态
   - 兼容多种推理服务 API 格式

2. 灵活性
   - 支持多种数据集格式（JSONL、CSV、JSON）
   - 支持自定义数据集和评估器
   - 支持多种评测场景（精度、性能、多轮对话）

3. 可扩展性
   - 基于注册表的插件化架构
   - 支持动态加载和注册新组件
   - 支持配置文件的模块化组合

4. 性能
   - 支持大规模数据集的高效处理
   - 支持多进程/多线程并行
   - 支持共享内存优化

5. 可观测性
   - 详细的评估结果记录
   - 支持断点续测和失败重试
   - 完整的日志和状态监控

### 二、设计约束

#### 2.1 技术约束

1. Python 版本：仅支持 Python 3.10、3.11、3.12
2. 依赖库：
   - HuggingFace Datasets（数据集管理）
   - MMEngine Config（配置管理）
   - NumPy（数值计算）
3. 内存约束：大规模数据集需分批处理，避免内存峰值

#### 2.2 数据格式约束

1. 数据集格式：
   - 必须包含 `train` 和 `test` 两个 split
   - 支持 Dataset 或 DatasetDict
   - 必须指定 `input_columns` 和 `output_column`

2. 配置格式：
   - 基于 Python 字典的配置
   - 必须包含必需字段（type、abbr 等）
   - 支持配置继承和合并

3. 评估结果格式：
   - 必须包含 `accuracy` 和 `details` 字段
   - `details` 为列表，每条记录包含评估详情

#### 2.3 业务约束

1. 多次独立推理：`k` 的最大值不能超过 `n`
2. 模型类型：同一任务不能混合使用 `local` 和 `service` 模型
3. 数据集标识：相同 `abbr` 的数据集会被视为同一任务

### 三、设计选型

#### 3.1 数据集管理

选型：HuggingFace Datasets
- 理由：
  - 生态成熟，支持多种格式
  - 提供高效的数据加载和处理
  - 支持大规模数据集的内存映射
  - 与 Transformers 生态集成

#### 3.2 配置管理

选型：MMEngine Config
- 理由：
  - 支持配置继承和合并
  - 支持 Python 代码配置
  - 提供配置验证和错误提示
  - 与 OpenCompass 兼容

#### 3.3 数据序列化

选型：JSON/JSONL
- 理由：
  - 人类可读
  - 跨语言兼容
  - 支持流式处理（JSONL）
  - 便于调试和验证

#### 3.4 性能数据存储

选型：NumPy 数组 + 共享内存
- 理由：
  - 数值计算高效
  - 支持多进程共享
  - 内存占用小
  - 便于统计分析

### 四、数据模型设计

#### 4.1 数据集数据模型

```python
# 数据集基础结构
Dataset/DatasetDict {
    'train': Dataset,      # 训练集
    'test': Dataset        # 测试集
}

# 数据集样本结构（以GSM8K为例）
Sample {
    'question': str,       # 输入问题
    'answer': str,         # 标准答案
    'subdivision': str,    # 数据集标识（自动添加）
    'idx': int,           # 原始索引（自动添加）
    'max_out_len': int?   # 最大输出长度（可选，性能测试用）
}

# 多模态样本结构
MultimodalSample {
    'question': str,
    'image': str,         # 图片路径或base64
    'answer': str,
    ...
}
```

#### 4.2 模型输出数据模型

```python
# 基础输出类
class Output:
    success: bool                    # 是否成功
    error_info: str                  # 错误信息
    time_points: List[float]         # 时间戳列表（性能测试）
    content: str | List[str]         # 模型输出内容
    reasoning_content: str | List[str] # 推理过程（可选）
    input_tokens: int                # 输入token数
    output_tokens: int               # 输出token数
    extra_perf_data: dict            # 额外性能数据
    extra_details_data: dict         # 额外详情数据
    input: str | List                # 输入内容
    uuid: str                        # 唯一标识
    turn_id: int                     # 轮次ID（多轮对话）

# 请求输出（性能测试）
class RequestOutput(Output):
    prediction: str                  # 最终预测结果
    # 继承所有Output字段
```

#### 4.3 配置数据模型

```python
# 模型配置
ModelConfig {
    'type': str,                     # 模型类型（类路径）
    'abbr': str,                     # 模型标识（必需）
    'attr': str,                     # 'local' 或 'service'（必需）
    'path': str,                     # 模型路径
    'host_ip': str,                  # 服务IP（service模式）
    'host_port': int,                # 服务端口（service模式）
    'max_out_len': int,              # 最大输出长度
    'batch_size': int,               # 批处理大小
    'generation_kwargs': dict,       # 生成参数
    ...
}

# 数据集配置
DatasetConfig {
    'type': str,                     # 数据集类型（类路径，必需）
    'abbr': str,                     # 数据集标识（必需）
    'path': str,                     # 数据集路径
    'reader_cfg': {                  # 读取器配置（必需）
        'input_columns': str | List[str],
        'output_column': str,
        'test_range': str?,          # 如 "[0:100]"
        'train_split': str,          # 默认 'train'
        'test_split': str            # 默认 'test'
    },
    'infer_cfg': {                   # 推理配置（必需）
        'prompt_template': dict,
        'retriever': dict,
        'inferencer': dict
    },
    'eval_cfg': {                    # 评估配置（必需）
        'evaluator': dict,
        'pred_role': str
    },
    'k': int | List[int],            # 重复因子
    'n': int                          # 重复次数
}

# 任务配置
TaskConfig {
    'models': List[ModelConfig],
    'datasets': List[DatasetConfig],
    'work_dir': str,
    'summarizer': dict,
    'cli_args': dict,
    'infer': dict?,                  # 推理阶段配置
    'eval': dict?                    # 评估阶段配置
}
```

#### 4.4 评估结果数据模型

```python
# 单次评估结果
EvaluationResult {
    'accuracy': float,               # 准确率（0-100）
    'details': List[DetailRecord],   # 详细评估结果
    'avg@{n}': float?,              # 平均准确率（n次独立推理）
    'pass@{k}': float?,             # pass@k指标
    'cons@{k}': float?,             # cons@k指标
    '{subdivision}/accuracy': float?, # 分类别准确率
    ...
}

# 详细评估记录
DetailRecord {
    'pred': str,                     # 预测结果
    'answer': str,                   # 标准答案
    'correct': bool,                 # 是否正确
    'example_abbr': str,             # 样本标识
    'predictions': List[dict]?,      # 多次推理的预测列表
    ...
}

# 性能评估结果
PerformanceResult {
    'E2EL': {                        # End-to-End Latency
        'total': {
            'Average': float,
            'Min': float,
            'Max': float,
            'Median': float,
            'P75': float,
            'P90': float,
            'P99': float,
            'N': int
        },
        ...
    },
    'TTFT': {...},                   # Time To First Token
    'TPUT': {...},                   # Throughput
    'QPS': {...},                    # Queries Per Second
    ...
}
```

#### 4.5 推理结果数据模型

```python
# 推理结果文件（JSONL格式）
PredictionRecord {
    'id': int,                       # 样本ID
    'input': str | List,             # 输入内容
    'prediction': str,                # 模型预测
    'reference': str,                 # 标准答案
    'metrics': dict?,                # 性能指标（性能测试）
    'uuid': str,                     # 唯一标识
    'turn_id': int?,                 # 轮次ID
    ...
}
```

#### 4.6 提示词数据模型

```python
# 单模态提示词
Prompt: str
# 示例: "Question: {question}\nAnswer: {answer}"

# 多模态提示词
MultimodalPrompt: List[Dict]
# 示例:
[
    {
        'role': 'user',
        'content': [
            {'type': 'text', 'text': 'What is in this image?'},
            {'type': 'image_url', 'image_url': {'url': '...'}}
        ]
    }
]

# 对话格式提示词
ChatPrompt: List[Dict]
# 示例:
[
    {'role': 'system', 'content': 'You are a helpful assistant.'},
    {'role': 'user', 'content': 'Hello'},
    {'role': 'assistant', 'content': 'Hi there!'}
]
```

#### 4.7 共享内存数据模型

```python
# 共享内存消息结构（性能测试）
MessageSharedMemory {
    'POST': int,                     # 已发送请求数
    'RECV': int,                     # 已接收响应数
    'FINISH': int,                   # 已完成请求数
    'FAIL': int,                     # 失败请求数
    'STATUS': int                    # 状态标志
}

# 共享内存数据块
SharedMemoryBlock {
    data: bytes,                     # 序列化的样本数据
    indexes: Dict[int, Tuple[int, int]]  # 索引映射 {idx: (offset, length)}
}
```

### 五、数据流转模型

#### 5.1 精度评测数据流

```
原始数据集文件 (JSONL/CSV)
    ↓
BaseDataset.load() → Dataset/DatasetDict
    ↓
DatasetReader → 添加metadata (subdivision, idx)
    ↓
repeated_dataset() → 重复n次（用于多次独立推理）
    ↓
Inferencer → 生成预测结果
    ↓
Output对象 → 提取prediction
    ↓
保存为predictions/*.jsonl
    ↓
Evaluator.score() → 计算准确率
    ↓
EvaluationResult → 保存为results/*.json
    ↓
Summarizer → 生成汇总报告
```

#### 5.2 性能评测数据流

```
合成/自定义数据集
    ↓
DatasetReader → 加载测试数据
    ↓
BaseApiInferencer → 发送请求（流式）
    ↓
RequestOutput → 记录时间戳和性能数据
    ↓
共享内存 → 实时状态更新
    ↓
保存为predictions/*.jsonl（含metrics）
    ↓
PerfMetricCalculator → 计算统计指标
    ↓
PerformanceResult → 保存为performances/*.json
    ↓
PerfSummarizer → 生成性能报告
```

### 六、数据模型特性

#### 6.1 可扩展性

- 基于注册表：新数据集/评估器通过注册机制集成
- 配置驱动：通过配置文件组合不同组件
- 接口抽象：基类定义统一接口，子类实现具体逻辑

#### 6.2 兼容性

- OpenCompass 兼容：数据集和配置格式兼容
- HuggingFace 兼容：使用 Datasets 库
- 多格式支持：JSONL、CSV、JSON 等

#### 6.3 性能优化

- 批量处理：支持批量数据加载和处理
- 共享内存：多进程间高效数据共享
- 延迟加载：按需加载数据集，减少内存占用

#### 6.4 可观测性

- 详细记录：记录每条样本的评估详情
- 状态监控：实时监控任务执行状态
- 断点续测：支持中断后继续执行

以上是 AISBench 数据模型设计的概述，涵盖设计目标、约束、选型和具体数据模型结构。