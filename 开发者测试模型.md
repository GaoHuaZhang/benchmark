分析 AISBench 的开发者测试模型。查看测试相关代码和配置：


[6 tools called]


继续查看测试相关代码：


[7 tools called]


继续查看测试相关代码：


[6 tools called]


基于代码分析，整理 AISBench 的开发者测试模型设计文档：

## AISBench 开发者测试模型设计文档

### 一、设计目标

#### 1.1 核心目标

1. 质量保证
   - 确保代码正确性和稳定性
   - 覆盖率目标：≥80%
   - 分支覆盖率：支持分支覆盖分析

2. 快速反馈
   - 单元测试快速执行
   - 支持并行测试
   - 实时测试结果反馈

3. 可维护性
   - 测试代码清晰易读
   - 测试与代码结构对应
   - 易于扩展和维护

4. 可重复性
   - 测试结果可重复
   - 支持 CI/CD 集成
   - 测试环境隔离

5. 全面性
   - 覆盖核心功能模块
   - 覆盖边界条件和异常场景
   - 覆盖不同运行模式

### 二、设计约束

#### 2.1 技术约束

1. Python 版本：仅支持 Python 3.10、3.11、3.12
2. 测试框架：
   - pytest（主要框架）
   - unittest（兼容性支持）
3. 依赖要求：
   - pytest
   - pytest-cov（覆盖率）
   - pytest-xdist（并行测试）
   - coverage

#### 2.2 环境约束

1. 测试隔离
   - 每个测试独立运行
   - 使用临时目录和文件
   - Mock 外部依赖

2. 资源限制
   - 避免使用真实模型和数据集
   - 限制测试数据规模
   - 控制测试执行时间

3. 外部依赖
   - Mock 网络请求
   - Mock 文件系统操作
   - Mock 多进程/多线程

#### 2.3 组织约束

1. 测试目录结构
   - `tests/UT/`：单元测试
   - `tests/ST/`：系统测试/集成测试
   - 测试目录与源码目录对应

2. 命名规范
   - 测试文件：`test_*.py` 或 `*_test.py`
   - 测试类：`Test*`
   - 测试方法：`test_*`

### 三、可测试性设计

#### 3.1 依赖注入

设计模式：依赖注入，便于 Mock

实现示例：
```python
# 模型构建通过注册表，可替换
from ais_bench.benchmark.registry import MODELS
model = MODELS.build(model_cfg)  # 可Mock

# 通过配置构建，便于测试
from ais_bench.benchmark.utils.config import build_model_from_cfg
model = build_model_from_cfg(model_cfg)  # 可Mock
```

#### 3.2 接口抽象

设计模式：接口抽象，便于测试替换

实现示例：
```python
# 基类定义接口
class BaseInferencer:
    @abstractmethod
    def get_data_list(self, retriever):
        pass

# 测试时可创建Mock实现
class MockInferencer(BaseInferencer):
    def get_data_list(self, retriever):
        return [{"test": "data"}]
```

#### 3.3 配置驱动

设计模式：配置驱动，便于测试配置

实现示例：
```python
# 通过配置对象传递参数
cfg = ConfigDict({
    "models": [...],
    "datasets": [...],
    "work_dir": temp_dir
})
# 测试时可使用简化配置
```

#### 3.4 工厂模式

设计模式：工厂模式，便于创建测试对象

实现示例：
```python
# 通过注册表构建对象
inferencer = ICL_INFERENCERS.build(inferencer_cfg)
# 测试时可注册Mock类
```

#### 3.5 状态隔离

设计模式：状态隔离，避免测试间影响

实现示例：
```python
# 使用临时目录
temp_dir = tempfile.mkdtemp()
# 每个测试使用独立的work_dir
cfg["work_dir"] = temp_dir
```

### 四、分层测试

#### 4.1 测试金字塔

```
                    /\
                   /  \
                  / E2E \         少量端到端测试
                 /______\
                /        \
               /Integration\       适量集成测试
              /____________\
             /              \
            /   Unit Tests    \    大量单元测试
           /__________________\
```

#### 4.2 单元测试层（UT）

范围：单个函数、类、方法

测试内容：
- 函数逻辑正确性
- 边界条件处理
- 异常处理
- 返回值验证

组织方式：
```
tests/UT/
├── cli/              # CLI层测试
├── tasks/            # 任务层测试
├── models/           # 模型层测试
├── datasets/         # 数据集层测试
├── openicl/          # OpenICL层测试
│   ├── icl_inferencer/
│   ├── icl_evaluator/
│   └── icl_retriever/
├── runners/          # 运行器层测试
├── partitioners/     # 分区器层测试
├── calculators/      # 计算器层测试
├── summarizers/      # 汇总器层测试
└── utils/            # 工具层测试
```

特点：
- 快速执行（毫秒级）
- 高覆盖率（目标≥80%）
- 完全隔离（Mock所有外部依赖）

#### 4.3 集成测试层（ST）

范围：多个模块协作

测试内容：
- 模块间接口
- 数据流转
- 配置加载和执行
- 端到端流程

组织方式：
```
tests/ST/
├── test_hf_backend.py        # HuggingFace后端集成测试
├── test_mindie_llm_api.py    # MindIE API集成测试
├── test_performance.py       # 性能测试集成
├── test_run_diff_datasets.py # 多数据集集成测试
└── test_service_api/         # 服务化API集成测试
```

特点：
- 中等执行时间（秒级到分钟级）
- 使用真实依赖（部分）
- 验证模块协作

#### 4.4 系统测试层（E2E）

范围：完整系统流程

测试内容：
- 完整评测流程
- 真实环境验证
- 性能基准测试
- 用户场景验证

特点：
- 较长执行时间（分钟级到小时级）
- 使用真实环境
- 验证完整功能

### 五、关键测试技术方案

#### 5.1 Mock 技术

##### 5.1.1 unittest.mock

使用场景：单元测试中的依赖隔离

实现示例：
```python
from unittest.mock import patch, MagicMock

class TestOpenICLApiInferTask(unittest.TestCase):
    @patch('ais_bench.benchmark.tasks.openicl_api_infer.ICL_INFERENCERS')
    @patch('ais_bench.benchmark.tasks.openicl_api_infer.AISLogger')
    def test_get_data_list(self, mock_logger_class, mock_inferencers):
        # Mock对象设置
        mock_inferencer = MagicMock()
        mock_inferencers.build.return_value = mock_inferencer
        mock_inferencer.get_data_list.return_value = [{"test": "data"}]

        # 执行测试
        task = self._create_task()
        result = task.get_data_list()

        # 验证调用
        mock_inferencers.build.assert_called_once()
        mock_inferencer.get_data_list.assert_called_once()
```

Mock 策略：
- Mock 外部服务（HTTP请求、文件系统）
- Mock 复杂依赖（模型加载、数据集加载）
- Mock 随机性（时间戳、UUID）
- Mock 多进程/多线程

##### 5.1.2 pytest fixtures

使用场景：测试数据准备和共享

实现示例：
```python
import pytest

class TestTaskManager:
    @pytest.fixture
    def setup_mocks(self):
        """设置所有需要的mock对象"""
        with patch('ais_bench.benchmark.cli.task_manager.ArgumentParser') as mock_arg_parser:
            with patch('ais_bench.benchmark.cli.config_manager.ConfigManager') as mock_config_manager:
                yield {
                    'mock_arg_parser': mock_arg_parser,
                    'mock_config_manager': mock_config_manager,
                }

    def test_init(self, setup_mocks):
        """测试TaskManager初始化"""
        mocks = setup_mocks
        task_manager = TaskManager()
        mocks['mock_arg_parser'].assert_called_once()
```

Fixture 类型：
- 数据 Fixture：测试数据准备
- Mock Fixture：Mock对象创建
- 环境 Fixture：临时目录、配置文件

#### 5.2 异步测试技术

##### 5.2.1 asyncio 测试

使用场景：测试异步函数

实现示例：
```python
import asyncio
from unittest.mock import mock

class TestBaseApiInferencer(unittest.TestCase):
    @mock.patch("...")
    def test_warmup(self, ...):
        inf = ConcreteApiInferencer(model_cfg={})

        async def run_test():
            await inf.warmup(data_list, warmup_times=3)
            self.assertEqual(call_count[0], 3)

        asyncio.run(run_test())
```

技术要点：
- 使用 `asyncio.run()` 运行异步测试
- Mock 异步函数和协程
- 测试异步并发场景

#### 5.3 共享内存测试技术

##### 5.3.1 共享内存 Mock

使用场景：测试多进程共享内存场景

实现示例：
```python
from multiprocessing import shared_memory
import pickle

def test_read_and_unpickle(self):
    """测试从共享内存读取并反序列化数据"""
    test_data = {"key": "value", "num": 42}
    pickled_data = pickle.dumps(test_data)

    shm = shared_memory.SharedMemory(create=True, size=len(pickled_data))
    try:
        shm.buf[:len(pickled_data)] = pickled_data
        index_data = (0, 0, len(pickled_data))
        result = inf._read_and_unpickle(shm.buf, index_data)
        self.assertEqual(result, test_data)
    finally:
        shm.close()
        shm.unlink()
```

技术要点：
- 创建真实的共享内存对象
- 测试序列化/反序列化
- 测试索引映射

#### 5.4 配置文件测试技术

##### 5.4.1 配置 Mock

使用场景：测试配置加载和验证

实现示例：
```python
def setUp(self):
    """设置测试环境"""
    self.temp_dir = tempfile.mkdtemp()
    self.cfg = ConfigDict({
        "models": [{
            "type": "test_model",
            "batch_size": 10,
        }],
        "datasets": [{
            "type": "test_dataset",
            "abbr": "test_dataset",
        }],
        "work_dir": self.temp_dir,
        "cli_args": {
            "pressure": False,
        }
    })
```

技术要点：
- 使用简化配置
- 使用临时目录
- 验证配置结构

#### 5.5 数据集测试技术

##### 5.5.1 数据集 Mock

使用场景：测试数据集加载和处理

实现示例：
```python
@patch('ais_bench.benchmark.tasks.openicl_api_infer.build_dataset_from_cfg')
def test_get_data_list(self, mock_build_dataset):
    # Mock数据集
    mock_dataset = MagicMock()
    mock_dataset.abbr = "test_dataset"
    mock_dataset.reader.dataset = {"test": Dataset.from_list([{"test": "data"}])}
    mock_build_dataset.return_value = mock_dataset

    # 执行测试
    result = task.get_data_list()

    # 验证
    mock_build_dataset.assert_called_once()
```

技术要点：
- Mock 数据集加载
- 使用小规模测试数据
- 验证数据格式

#### 5.6 模型测试技术

##### 5.6.1 模型 Mock

使用场景：测试模型接口和交互

实现示例：
```python
class DummyModel:
    """测试用的虚拟模型"""
    def __init__(self):
        self.max_out_len = 16
        self.is_api = False

    def parse_template(self, prompt, mode="gen"):
        return prompt

    def generate(self, inputs, max_out_len, **kwargs):
        return [RequestOutput() for _ in inputs]

@mock.patch("...build_model_from_cfg")
def test_init(self, m_build):
    m_build.return_value = DummyModel()
    inf = ConcreteApiInferencer(model_cfg={})
    # 测试逻辑
```

技术要点：
- 创建轻量级 Mock 模型
- 模拟模型行为
- 避免加载真实模型

#### 5.7 覆盖率测试技术

##### 5.7.1 覆盖率配置

实现位置：`pytest.ini`, `.coveragerc`

配置要点：
```ini
[coverage:run]
source = ais_bench
branch = True  # 启用分支覆盖
omit =
    */tests/*
    */__pycache__/*

[coverage:report]
fail_under = 80  # 覆盖率阈值80%
show_missing = True
precision = 2
```

覆盖率指标：
- 行覆盖率：≥80%
- 分支覆盖率：支持分支覆盖分析
- 函数覆盖率：统计函数覆盖情况

##### 5.7.2 覆盖率报告

报告格式：
- HTML 报告：`test_reports/htmlcov/index.html`
- XML 报告：`test_reports/coverage.xml`
- JSON 报告：`test_reports/coverage.json`

排除规则：
- 测试代码本身
- 第三方库代码
- 抽象方法和协议类
- 调试代码

#### 5.8 并行测试技术

##### 5.8.1 pytest-xdist

使用场景：加速测试执行

实现方式：
```python
# 自动检测worker数量
cmd.extend(['-n', 'auto'])

# 指定worker数量
cmd.extend(['-n', '4'])
```

技术要点：
- 进程级并行
- 自动负载均衡
- 测试隔离

#### 5.9 测试数据管理

##### 5.9.1 临时文件管理

实现方式：
```python
def setUp(self):
    """设置测试环境"""
    self.temp_dir = tempfile.mkdtemp()

def tearDown(self):
    """清理测试环境"""
    import shutil
    if os.path.exists(self.temp_dir):
        shutil.rmtree(self.temp_dir)
```

技术要点：
- 使用 `tempfile.mkdtemp()` 创建临时目录
- 测试后自动清理
- 避免测试间干扰

##### 5.9.2 测试数据生成

实现方式：
```python
# 生成测试数据
test_data = {
    "id": 0,
    "prompt": "test prompt",
    "data_abbr": "test_dataset",
    "index": 0,
    "max_out_len": 512
}

# 使用工厂函数
def create_test_task_cfg():
    return ConfigDict({
        "models": [...],
        "datasets": [...],
        "work_dir": tempfile.mkdtemp()
    })
```

#### 5.10 异常测试技术

##### 5.10.1 异常场景测试

实现方式：
```python
def test_invalid_batch_size(self):
    """测试无效的batch_size"""
    with self.assertRaises(ParameterValueError) as cm:
        task = OpenICLApiInferTask(cfg_with_invalid_batch_size)
    self.assertIn("batch_size", str(cm.exception))

def test_memory_usage_too_high(self):
    """测试内存使用过高"""
    large_dataset_bytes = 10**12  # 1TB
    with self.assertRaises(AISBenchRuntimeError) as cm:
        check_virtual_memory_usage(large_dataset_bytes)
    self.assertIn("memory usage too high", str(cm.exception).lower())
```

测试场景：
- 参数验证失败
- 资源限制超限
- 文件操作失败
- 网络请求失败

#### 5.11 性能测试技术

##### 5.11.1 性能基准测试

实现方式：
```python
import time

def test_inference_performance(self):
    """测试推理性能"""
    start_time = time.perf_counter()
    result = inferencer.inference(data_list)
    end_time = time.perf_counter()

    duration = end_time - start_time
    self.assertLess(duration, 1.0, "推理时间应小于1秒")
```

测试指标：
- 执行时间
- 内存使用
- 并发性能

#### 5.12 集成测试技术

##### 5.12.1 Monkey Patching

使用场景：系统测试中的依赖替换

实现示例：
```python
def test_hf_base_model_all_gsm8k_str(self, monkeypatch):
    """测试HuggingFace Base模型完整流程"""
    # Mock命令行参数
    monkeypatch.setattr('sys.argv', [
        "ais_bench", "--models", "hf_base_model",
        "--datasets", "gsm8k_gen_4_shot_cot_str"
    ])

    # Mock模型生成
    monkeypatch.setattr(
        "ais_bench.benchmark.models.huggingface_above_v4_33.HuggingFaceBaseModel.generate",
        lambda self, inputs, *arg, **kwargs: ["123" for _ in inputs]
    )

    # Mock时间戳
    monkeypatch.setattr(
        "ais_bench.benchmark.cli.main.get_current_time_str",
        lambda *arg: "gsm8k_gen_4_shot_str"
    )

    # 执行主函数
    main()

    # 验证输出文件
    assert os.path.exists(infer_outputs_json_path)
```

技术要点：
- 替换系统级依赖
- 控制执行环境
- 验证完整流程

### 六、测试组织结构

#### 6.1 测试目录结构

```
tests/
├── UT/                          # 单元测试
│   ├── cli/                     # CLI层测试
│   ├── tasks/                   # 任务层测试
│   ├── models/                  # 模型层测试
│   │   ├── api_models/         # API模型测试
│   │   └── local_models/        # 本地模型测试
│   ├── datasets/                # 数据集测试
│   ├── openicl/                 # OpenICL测试
│   │   ├── icl_inferencer/      # 推理器测试
│   │   ├── icl_evaluator/       # 评估器测试
│   │   └── icl_retriever/       # 检索器测试
│   ├── runners/                 # 运行器测试
│   ├── partitioners/            # 分区器测试
│   ├── calculators/             # 计算器测试
│   ├── summarizers/             # 汇总器测试
│   └── utils/                   # 工具测试
├── ST/                          # 系统测试
│   ├── test_hf_backend.py       # HF后端测试
│   ├── test_performance.py      # 性能测试
│   └── test_service_api/        # 服务API测试
├── pytest.ini                   # pytest配置
└── run_tests.py                 # 测试运行脚本
```

#### 6.2 测试文件命名

- 单元测试：`test_<module_name>.py`
- 系统测试：`test_<feature>.py`
- 测试类：`Test<ClassName>`
- 测试方法：`test_<method_name>`

### 七、测试执行流程

#### 7.1 测试执行流程

```
1. 依赖检查
   ↓
2. 清理缓存
   ↓
3. 发现测试文件
   ↓
4. 执行测试（pytest）
   ├── 单元测试（快速）
   ├── 集成测试（中等）
   └── 系统测试（慢速）
   ↓
5. 收集覆盖率数据
   ↓
6. 生成覆盖率报告
   ├── HTML报告
   ├── XML报告
   └── JSON报告
   ↓
7. 生成测试摘要
   ↓
8. 输出测试结果
```

#### 7.2 测试标记系统

标记定义：
```ini
markers =
    slow: 标记为慢速测试
    integration: 集成测试
    unit: 单元测试
    smoke: 冒烟测试
    regression: 回归测试
    asyncio: 异步测试
```

使用方式：
```python
@pytest.mark.slow
def test_slow_operation():
    pass

@pytest.mark.integration
def test_integration_flow():
    pass
```

执行特定标记的测试：
```bash
pytest -m "not slow"  # 排除慢速测试
pytest -m integration  # 仅执行集成测试
```

### 八、测试最佳实践

#### 8.1 测试编写原则

1. AAA 模式（Arrange-Act-Assert）
```python
def test_example(self):
    # Arrange: 准备测试数据
    cfg = create_test_config()

    # Act: 执行被测试代码
    result = function_under_test(cfg)

    # Assert: 验证结果
    self.assertEqual(result, expected_value)
```

2. 测试独立性
- 每个测试独立运行
- 不依赖其他测试
- 不依赖执行顺序

3. 测试可读性
- 清晰的测试名称
- 充分的注释说明
- 合理的测试组织

4. 测试覆盖
- 覆盖正常路径
- 覆盖异常路径
- 覆盖边界条件

#### 8.2 测试维护策略

1. 测试重构
- 提取公共测试代码
- 使用 Fixture 共享设置
- 保持测试代码简洁

2. 测试更新
- 代码变更时同步更新测试
- 删除过时测试
- 添加新功能测试

3. 测试审查
- 代码审查时审查测试
- 确保测试质量
- 验证测试有效性

### 九、测试工具链

#### 9.1 核心工具

| 工具 | 用途 | 版本要求 |
|------|------|---------|
| pytest | 测试框架 | ≥7.0 |
| pytest-cov | 覆盖率插件 | ≥4.0 |
| pytest-xdist | 并行测试 | ≥3.0 |
| coverage | 覆盖率工具 | ≥7.0 |
| unittest.mock | Mock工具 | Python内置 |

#### 9.2 辅助工具

- `run_tests.py`：自定义测试运行器
- `pytest.ini`：pytest 配置
- `.coveragerc`：覆盖率配置

### 十、测试指标与监控

#### 10.1 测试指标

1. 覆盖率指标
   - 行覆盖率：≥80%
   - 分支覆盖率：统计分支覆盖
   - 函数覆盖率：统计函数覆盖

2. 测试执行指标
   - 测试总数
   - 通过率
   - 失败率
   - 跳过率

3. 测试性能指标
   - 测试执行时间
   - 平均测试时间
   - 最长测试时间

#### 10.2 持续监控

1. CI/CD 集成
   - 每次提交运行测试
   - 覆盖率检查
   - 测试结果报告

2. 测试报告
   - HTML 覆盖率报告
   - 测试摘要报告
   - 失败测试详情

以上是 AISBench 的开发者测试模型设计，涵盖设计目标、约束、可测试性设计、分层测试和关键测试技术方案。


查看现有测试模型文档和测试代码，补充关键测试技术方案。


[6 tools called]


继续查看测试代码，了解测试技术方案：


[4 tools called]


查看开发者测试模型文档的完整结构：


[2 tools called]


补充关键测试技术方案，按指定格式整理：

```markdown:/home/theone/code/dev_branch/benchmark_github/开发者测试模型.md
### 五、关键测试技术方案

#### 5.1 测试工程设计

##### 5.1.1 测试框架选型

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **pytest**（最终方案） | 1. 丰富的插件生态（pytest-cov、pytest-xdist、pytest-mock）<br>2. 灵活的fixture机制<br>3. 参数化测试支持<br>4. 清晰的断言信息<br>5. 支持异步测试 | 1. 需要额外学习fixture语法<br>2. 插件依赖管理 | 单元测试、集成测试 |
| unittest | 1. Python标准库，无需安装<br>2. 面向对象设计<br>3. 与IDE集成良好 | 1. 功能相对简单<br>2. 缺少参数化测试<br>3. 断言信息不够详细 | 简单单元测试、兼容性测试 |
| nose2 | 1. 兼容unittest<br>2. 插件支持 | 1. 社区活跃度低<br>2. 功能不如pytest丰富 | 不推荐 |

**最终方案选择**：**pytest**

**选择理由**：
- 丰富的插件生态满足AISBench的复杂测试需求（覆盖率、并行测试、Mock）
- Fixture机制便于测试数据管理和环境准备
- 参数化测试支持多场景测试
- 活跃的社区和良好的文档支持

**分层映射**：
- **单元测试层（UT）**：主要使用pytest，兼容unittest.TestCase
- **集成测试层（ST）**：使用pytest + pytest-mock
- **系统测试层（E2E）**：使用pytest + 真实环境

##### 5.1.2 测试组织结构

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **镜像源码结构**（最终方案） | 1. 测试与源码一一对应<br>2. 易于定位测试文件<br>3. 便于维护 | 1. 目录层级较深 | 大型项目 |
| 扁平结构 | 1. 目录层级浅<br>2. 查找简单 | 1. 难以对应源码<br>2. 文件过多时混乱 | 小型项目 |
| 功能模块分组 | 1. 按功能组织<br>2. 便于功能测试 | 1. 与源码结构不一致<br>2. 维护成本高 | 功能驱动项目 |

**最终方案选择**：**镜像源码结构**

**实现方式**：
```
tests/
├── UT/                    # 单元测试
│   ├── cli/              # 对应 ais_bench/benchmark/cli/
│   ├── tasks/            # 对应 ais_bench/benchmark/tasks/
│   ├── models/           # 对应 ais_bench/benchmark/models/
│   ├── datasets/         # 对应 ais_bench/benchmark/datasets/
│   ├── openicl/          # 对应 ais_bench/benchmark/openicl/
│   └── utils/            # 对应 ais_bench/benchmark/utils/
└── ST/                    # 集成测试
    ├── test_hf_backend.py
    └── test_service_api/
```

**分层映射**：
- **单元测试层（UT）**：严格镜像源码结构，每个模块对应一个测试目录
- **集成测试层（ST）**：按功能场景组织，不严格对应源码结构
- **系统测试层（E2E）**：按用户场景组织，独立目录

##### 5.1.3 测试发现与执行

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **pytest自动发现**（最终方案） | 1. 自动发现测试文件<br>2. 支持标记过滤<br>3. 支持路径过滤 | 1. 需要遵循命名规范 | 标准pytest项目 |
| 手动指定测试文件 | 1. 精确控制<br>2. 灵活性高 | 1. 维护成本高<br>2. 容易遗漏 | 特殊场景 |
| 测试清单文件 | 1. 可版本控制<br>2. 可配置执行顺序 | 1. 维护成本高<br>2. 容易过时 | 复杂测试场景 |

**最终方案选择**：**pytest自动发现 + 自定义测试运行器**

**实现方式**：
- 使用 `pytest.ini` 配置测试发现规则
- 使用 `run_tests.py` 自定义测试运行器，支持：
  - 自动推断源码目录（用于覆盖率）
  - 并行测试执行（pytest-xdist）
  - 覆盖率报告生成
  - 测试结果汇总

**分层映射**：
- **单元测试层（UT）**：自动发现 + 并行执行
- **集成测试层（ST）**：自动发现 + 顺序执行（避免资源竞争）
- **系统测试层（E2E）**：手动指定 + 顺序执行

#### 5.2 运行环境

##### 5.2.1 测试环境隔离

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **临时目录 + Mock**（最终方案） | 1. 轻量级<br>2. 快速执行<br>3. 完全隔离 | 1. 需要Mock文件系统操作 | 单元测试、集成测试 |
| Docker容器 | 1. 完全隔离<br>2. 环境一致性<br>3. 可重复 | 1. 启动开销大<br>2. 需要Docker环境 | 系统测试、CI/CD |
| 虚拟机 | 1. 完全隔离<br>2. 接近真实环境 | 1. 资源消耗大<br>2. 启动慢 | 系统测试 |
| 共享测试环境 | 1. 资源消耗小<br>2. 启动快 | 1. 测试间可能相互影响<br>2. 难以并行 | 不推荐 |

**最终方案选择**：**分层环境策略**

**实现方式**：

1. **单元测试层（UT）**：临时目录 + Mock
   ```python
   def setUp(self):
       self.temp_dir = tempfile.mkdtemp()
       self.cfg = ConfigDict({"work_dir": self.temp_dir})

   def tearDown(self):
       shutil.rmtree(self.temp_dir)
   ```

2. **集成测试层（ST）**：临时目录 + 部分真实依赖
   ```python
   @pytest.fixture(scope="function")
   def test_data_path():
       path = tempfile.mkdtemp()
       yield path
       shutil.rmtree(path)
   ```

3. **系统测试层（E2E）**：独立测试目录 + 真实环境
   ```python
   @classmethod
   def setup_class(cls):
       cls.test_data_path = os.path.join(os.path.dirname(__file__), "../testdatas")
       if os.path.exists(cls.test_data_path):
           shutil.rmtree(cls.test_data_path)
       os.makedirs(cls.test_data_path)
   ```

**分层映射**：
- **单元测试层（UT）**：完全隔离，使用临时目录和Mock
- **集成测试层（ST）**：部分隔离，使用临时目录但允许真实依赖
- **系统测试层（E2E）**：共享环境，使用独立测试目录

##### 5.2.2 Python环境管理

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **Conda**（最终方案） | 1. 环境隔离好<br>2. 支持多Python版本<br>3. 包管理完善 | 1. 体积较大<br>2. 启动稍慢 | 开发环境、CI/CD |
| venv | 1. Python标准库<br>2. 轻量级 | 1. 仅支持单一Python版本<br>2. 包管理功能弱 | 简单项目 |
| virtualenv | 1. 功能丰富<br>2. 兼容性好 | 1. 需要额外安装<br>2. 配置复杂 | 传统项目 |
| 系统Python | 1. 无需配置<br>2. 启动快 | 1. 环境污染<br>2. 版本冲突 | 不推荐 |

**最终方案选择**：**Conda + 版本锁定**

**实现方式**：
- 使用Conda创建独立测试环境
- 支持Python 3.10、3.11、3.12多版本测试
- 使用 `requirements.txt` 锁定依赖版本

**分层映射**：
- **单元测试层（UT）**：Conda环境 + 最小依赖集
- **集成测试层（ST）**：Conda环境 + 完整依赖集
- **系统测试层（E2E）**：Conda环境 + 完整依赖集 + 真实服务

#### 5.3 测试替身设计

##### 5.3.1 Mock框架选型

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **unittest.mock**（最终方案） | 1. Python标准库<br>2. 功能完善<br>3. 与pytest兼容<br>4. 支持异步Mock | 1. API相对复杂 | 单元测试、集成测试 |
| pytest-mock | 1. pytest集成好<br>2. 简化Mock使用 | 1. 功能基于unittest.mock<br>2. 额外依赖 | pytest项目 |
| Mockito | 1. 语法简洁<br>2. 行为验证 | 1. 需要额外安装<br>2. 社区较小 | Java风格项目 |
| Faker | 1. 生成真实测试数据<br>2. 支持多种数据类型 | 1. 主要用于数据生成<br>2. 不是Mock框架 | 数据生成场景 |

**最终方案选择**：**unittest.mock + pytest-mock**

**选择理由**：
- unittest.mock是标准库，无需额外依赖
- pytest-mock提供pytest风格的Mock fixture，简化使用
- 支持异步函数Mock
- 支持上下文管理器（patch）

**分层映射**：
- **单元测试层（UT）**：unittest.mock，Mock所有外部依赖
- **集成测试层（ST）**：unittest.mock + pytest-mock，Mock部分外部依赖
- **系统测试层（E2E）**：pytest monkeypatch，Mock系统级依赖（如时间、随机数）

##### 5.3.2 Mock策略设计

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **分层Mock策略**（最终方案） | 1. 不同层级不同Mock策略<br>2. 平衡真实性和隔离性 | 1. 需要设计Mock层次 | 分层测试架构 |
| 完全Mock | 1. 完全隔离<br>2. 执行快速 | 1. 可能遗漏集成问题<br>2. Mock复杂度高 | 单元测试 |
| 真实依赖 | 1. 真实场景<br>2. 发现集成问题 | 1. 执行慢<br>2. 环境依赖 | 系统测试 |

**最终方案选择**：**分层Mock策略**

**实现方式**：

1. **单元测试层（UT）**：完全Mock策略
   ```python
   @patch('ais_bench.benchmark.tasks.openicl_api_infer.ICL_INFERENCERS')
   @patch('ais_bench.benchmark.tasks.openicl_api_infer.AISLogger')
   def test_get_data_list(self, mock_logger_class, mock_inferencers):
       mock_inferencer = MagicMock()
       mock_inferencers.build.return_value = mock_inferencer
       # 测试逻辑
   ```

2. **集成测试层（ST）**：部分Mock策略
   ```python
   @pytest.fixture
   def setup_mocks(self):
       with patch('ais_bench.benchmark.cli.task_manager.ArgumentParser') as mock_arg_parser:
           with patch('ais_bench.benchmark.cli.config_manager.ConfigManager') as mock_config_manager:
               yield {'mock_arg_parser': mock_arg_parser, ...}
   ```

3. **系统测试层（E2E）**：最小Mock策略
   ```python
   def test_hf_backend(self, monkeypatch):
       monkeypatch.setattr('sys.argv', ["ais_bench", "--models", "hf_base_model", ...])
       monkeypatch.setattr("...HuggingFaceBaseModel.generate", lambda self, inputs, *arg, **kwargs: [fake_prediction for _ in range(len(inputs))])
       main()  # 真实执行
   ```

**Mock对象类型**：

| Mock类型 | 使用场景 | 实现方式 | 分层映射 |
|---------|---------|---------|---------|
| MagicMock | 通用Mock对象 | `MagicMock()` | UT、ST |
| Mock | 需要严格类型检查 | `Mock(spec=ClassName)` | UT |
| patch装饰器 | 函数/方法Mock | `@patch('module.function')` | UT、ST |
| patch上下文 | 临时Mock | `with patch(...):` | UT、ST |
| monkeypatch | 系统级Mock | `monkeypatch.setattr(...)` | ST、E2E |

##### 5.3.3 异步Mock设计

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **asyncio.run() + Mock**（最终方案） | 1. 标准库支持<br>2. 简单直接<br>3. 兼容性好 | 1. 需要手动管理事件循环 | 异步函数测试 |
| pytest-asyncio | 1. pytest集成好<br>2. 自动管理事件循环 | 1. 需要额外依赖<br>2. 配置复杂 | pytest异步测试 |
| AsyncMock | 1. 专门用于异步Mock<br>2. 语法简洁 | 1. Python 3.8+<br>2. 功能相对简单 | 简单异步Mock |

**最终方案选择**：**asyncio.run() + unittest.mock.AsyncMock**

**实现方式**：
```python
import asyncio
from unittest.mock import AsyncMock

class TestBaseApiInferencer(unittest.TestCase):
    @mock.patch("...")
    def test_warmup(self, ...):
        inf = ConcreteApiInferencer(model_cfg={})

        async def run_test():
            await inf.warmup(data_list, warmup_times=3)
            self.assertEqual(call_count[0], 3)

        asyncio.run(run_test())
```

**分层映射**：
- **单元测试层（UT）**：asyncio.run() + AsyncMock
- **集成测试层（ST）**：pytest-asyncio + AsyncMock
- **系统测试层（E2E）**：真实异步执行

#### 5.4 DSL设计

##### 5.4.1 测试配置DSL

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **ConfigDict + Fixture**（最终方案） | 1. 与源码配置一致<br>2. 类型安全<br>3. 易于扩展 | 1. 需要了解配置结构 | 配置驱动测试 |
| YAML配置文件 | 1. 可读性好<br>2. 易于编辑 | 1. 需要解析<br>2. 类型检查弱 | 复杂配置场景 |
| JSON配置文件 | 1. 标准格式<br>2. 易于解析 | 1. 可读性差<br>2. 不支持注释 | 简单配置场景 |
| Python字典 | 1. 灵活<br>2. 无需解析 | 1. 可读性一般<br>2. 难以版本控制 | 简单测试场景 |

**最终方案选择**：**ConfigDict + pytest Fixture**

**实现方式**：
```python
@pytest.fixture
def base_config():
    """基础测试配置"""
    return ConfigDict({
        "models": [{
            "type": "test_model",
            "batch_size": 10,
            "generation_kwargs": {"num_return_sequences": 1}
        }],
        "datasets": [{
            "type": "test_dataset",
            "abbr": "test_dataset",
            "infer_cfg": {"inferencer": {"type": "test_inferencer"}}
        }],
        "work_dir": tempfile.mkdtemp(),
        "cli_args": {"pressure": False, "num_warmups": 1}
    })

def test_task_with_config(base_config):
    task = OpenICLApiInferTask(base_config)
    # 测试逻辑
```

**分层映射**：
- **单元测试层（UT）**：简化ConfigDict，仅包含必要字段
- **集成测试层（ST）**：完整ConfigDict，接近真实配置
- **系统测试层（E2E）**：真实配置文件，从文件加载

##### 5.4.2 测试数据DSL

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **Python数据结构**（最终方案） | 1. 灵活<br>2. 易于构造<br>3. 类型安全 | 1. 代码量较大 | 复杂数据结构 |
| JSON文件 | 1. 可读性好<br>2. 易于编辑 | 1. 需要解析<br>2. 类型检查弱 | 大量测试数据 |
| 数据生成器 | 1. 自动生成<br>2. 支持参数化 | 1. 需要实现生成器<br>2. 可读性差 | 大数据量测试 |
| 模板系统 | 1. 可复用<br>2. 易于扩展 | 1. 需要模板引擎<br>2. 学习成本 | 复杂数据场景 |

**最终方案选择**：**Python数据结构 + Fixture工厂**

**实现方式**：
```python
@pytest.fixture
def sample_data():
    """示例测试数据"""
    return [{"test": "data", "id": i} for i in range(10)]

@pytest.fixture
def data_factory():
    """数据工厂函数"""
    def _create_data(count=10, **kwargs):
        return [{"id": i, **kwargs} for i in range(count)]
    return _create_data

def test_with_data(sample_data, data_factory):
    data = data_factory(count=5, type="test")
    # 测试逻辑
```

**分层映射**：
- **单元测试层（UT）**：最小数据集，Python内联构造
- **集成测试层（ST）**：中等数据集，Fixture工厂构造
- **系统测试层（E2E）**：真实数据集，从文件加载

#### 5.5 数据构造设计

##### 5.5.1 测试数据生成策略

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **Fixture工厂 + 参数化**（最终方案） | 1. 灵活<br>2. 可复用<br>3. 支持参数化 | 1. 需要设计工厂函数 | 多场景测试 |
| 硬编码数据 | 1. 简单直接<br>2. 可读性好 | 1. 难以复用<br>2. 维护成本高 | 简单测试场景 |
| 数据生成库（Faker） | 1. 生成真实数据<br>2. 支持多种类型 | 1. 需要额外依赖<br>2. 数据不可控 | 大数据量测试 |
| 模板系统 | 1. 可复用<br>2. 易于扩展 | 1. 需要模板引擎<br>2. 学习成本 | 复杂数据场景 |

**最终方案选择**：**Fixture工厂 + pytest参数化**

**实现方式**：
```python
@pytest.fixture
def model_config_factory():
    """模型配置工厂"""
    def _create_model_config(batch_size=10, **kwargs):
        return ConfigDict({
            "type": "test_model",
            "batch_size": batch_size,
            "generation_kwargs": {"num_return_sequences": 1},
            **kwargs
        })
    return _create_model_config

@pytest.mark.parametrize("batch_size,expected", [
    (1, 1),
    (10, 10),
    (100, 100),
])
def test_batch_size(model_config_factory, batch_size, expected):
    config = model_config_factory(batch_size=batch_size)
    assert config["batch_size"] == expected
```

**分层映射**：
- **单元测试层（UT）**：Fixture工厂，最小数据集
- **集成测试层（ST）**：Fixture工厂 + 参数化，中等数据集
- **系统测试层（E2E）**：真实数据集文件，完整数据集

##### 5.5.2 共享内存数据构造

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **真实共享内存**（最终方案） | 1. 真实场景<br>2. 测试完整流程 | 1. 需要清理资源<br>2. 跨平台兼容性 | 多进程测试 |
| Mock共享内存 | 1. 快速执行<br>2. 无需清理 | 1. 可能遗漏真实问题 | 简单测试场景 |
| 内存映射文件 | 1. 持久化<br>2. 可调试 | 1. 需要文件系统<br>2. 性能较差 | 调试场景 |

**最终方案选择**：**真实共享内存 + 资源清理**

**实现方式**：
```python
def test_read_and_unpickle(self):
    """测试从共享内存读取并反序列化数据"""
    test_data = {"key": "value", "num": 42}
    pickled_data = pickle.dumps(test_data)

    shm = shared_memory.SharedMemory(create=True, size=len(pickled_data))
    try:
        shm.buf[:len(pickled_data)] = pickled_data
        index_data = (0, 0, len(pickled_data))
        result = inf._read_and_unpickle(shm.buf, index_data)
        self.assertEqual(result, test_data)
    finally:
        shm.close()
        shm.unlink()  # 清理资源
```

**分层映射**：
- **单元测试层（UT）**：真实共享内存，小数据量
- **集成测试层（ST）**：真实共享内存，中等数据量
- **系统测试层（E2E）**：真实共享内存，大数据量

#### 5.6 夹具设计

##### 5.6.1 Fixture作用域设计

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **分层作用域策略**（最终方案） | 1. 平衡性能和隔离<br>2. 灵活控制 | 1. 需要设计作用域 | 分层测试架构 |
| 全部function作用域 | 1. 完全隔离<br>2. 安全性高 | 1. 性能开销大<br>2. 重复创建 | 简单测试场景 |
| 全部module作用域 | 1. 性能好<br>2. 创建次数少 | 1. 测试间可能相互影响<br>2. 难以并行 | 不推荐 |

**最终方案选择**：**分层作用域策略**

**实现方式**：

1. **单元测试层（UT）**：function作用域（完全隔离）
   ```python
   @pytest.fixture(scope="function")
   def temp_dir():
       """每个测试函数独立的临时目录"""
       path = tempfile.mkdtemp()
       yield path
       shutil.rmtree(path)
   ```

2. **集成测试层（ST）**：function作用域 + class作用域（部分共享）
   ```python
   @pytest.fixture(scope="class")
   def test_data_path():
       """类级别共享的测试数据目录"""
       path = tempfile.mkdtemp()
       yield path
       shutil.rmtree(path)
   ```

3. **系统测试层（E2E）**：class作用域（共享环境）
   ```python
   @pytest.fixture(scope="class")
   def e2e_test_env():
       """端到端测试环境"""
       # 创建测试环境
       yield env
       # 清理测试环境
   ```

**Fixture类型设计**：

| Fixture类型 | 作用域 | 使用场景 | 分层映射 |
|-----------|--------|---------|---------|
| 数据Fixture | function | 测试数据准备 | UT、ST |
| Mock Fixture | function | Mock对象创建 | UT、ST |
| 环境Fixture | function/class | 临时目录、配置文件 | UT、ST、E2E |
| 服务Fixture | class/session | 测试服务启动 | ST、E2E |

##### 5.6.2 Fixture组合设计

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **Fixture依赖注入**（最终方案） | 1. 灵活组合<br>2. 自动管理依赖<br>3. 易于维护 | 1. 需要理解依赖关系 | pytest项目 |
| 手动组合 | 1. 控制精确<br>2. 易于理解 | 1. 代码重复<br>2. 维护成本高 | 简单场景 |
| Fixture继承 | 1. 代码复用<br>2. 易于扩展 | 1. 依赖关系复杂<br>2. 难以理解 | 复杂场景 |

**最终方案选择**：**Fixture依赖注入**

**实现方式**：
```python
@pytest.fixture
def temp_dir():
    """临时目录Fixture"""
    path = tempfile.mkdtemp()
    yield path
    shutil.rmtree(path)

@pytest.fixture
def base_config(temp_dir):
    """基础配置Fixture，依赖temp_dir"""
    return ConfigDict({
        "work_dir": temp_dir,
        "models": [...],
        "datasets": [...]
    })

@pytest.fixture
def task(base_config):
    """任务Fixture，依赖base_config"""
    return OpenICLApiInferTask(base_config)

def test_task(task):
    """测试函数，自动注入task Fixture"""
    result = task.get_data_list()
    assert result is not None
```

**分层映射**：
- **单元测试层（UT）**：简单Fixture组合，function作用域
- **集成测试层（ST）**：复杂Fixture组合，function/class作用域
- **系统测试层（E2E）**：环境Fixture组合，class/session作用域

#### 5.7 匹配器设计

##### 5.7.1 断言匹配器选型

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **pytest断言 + 自定义匹配器**（最终方案） | 1. 清晰的错误信息<br>2. 支持复杂断言<br>3. 易于扩展 | 1. 需要学习语法 | 标准pytest项目 |
| unittest断言 | 1. 标准库<br>2. 简单直接 | 1. 错误信息不够详细<br>2. 功能有限 | unittest项目 |
| Hamcrest | 1. 可读性好<br>2. 丰富的匹配器 | 1. 需要额外依赖<br>2. 学习成本 | Java风格项目 |
| assertpy | 1. 流畅API<br>2. 可读性好 | 1. 需要额外依赖<br>2. 社区较小 | 简单项目 |

**最终方案选择**：**pytest断言 + 自定义匹配器**

**实现方式**：
```python
# 标准pytest断言
def test_basic_assert():
    assert result == expected
    assert result in [1, 2, 3]
    assert result is not None

# 自定义匹配器
def assert_output_valid(output):
    """自定义输出验证匹配器"""
    assert output.success is True
    assert output.content is not None
    assert len(output.content) > 0
    return True

def test_output(output):
    assert assert_output_valid(output)
```

**分层映射**：
- **单元测试层（UT）**：标准pytest断言 + 简单自定义匹配器
- **集成测试层（ST）**：标准pytest断言 + 复杂自定义匹配器
- **系统测试层（E2E）**：标准pytest断言 + 文件/数据验证匹配器

##### 5.7.2 Mock验证匹配器

**备选方案对比**：

| 方案 | 优点 | 缺点 | 适用场景 |
|------|------|------|---------|
| **unittest.mock断言**（最终方案） | 1. 功能完善<br>2. 标准库<br>3. 支持复杂验证 | 1. API相对复杂 | Mock验证 |
| pytest-mock断言 | 1. pytest风格<br>2. 语法简洁 | 1. 功能基于unittest.mock | pytest项目 |
| 手动验证 | 1. 灵活<br>2. 控制精确 | 1. 代码重复<br>2. 维护成本高 | 简单场景 |

**最终方案选择**：**unittest.mock断言 + pytest-mock**

**实现方式**：
```python
# 调用验证
mock_inferencers.build.assert_called_once()
mock_inferencer.get_data_list.assert_called_once_with(retriever)

# 调用次数验证
assert mock_func.call_count == 3

# 调用参数验证
mock_func.assert_any_call(arg1, arg2, kwarg1="value")

# 调用顺序验证
from unittest.mock import call
mock_func.assert_has_calls([call(1), call(2), call(3)])
```

**分层映射**：
- **单元测试层（UT）**：严格Mock验证，验证所有调用
- **集成测试层（ST）**：部分Mock验证，验证关键调用
- **系统测试层（E2E）**：最小Mock验证，仅验证结果

#### 5.8 技术方案分层映射总结

| 技术方案 | 单元测试层（UT） | 集成测试层（ST） | 系统测试层（E2E） |
|---------|----------------|----------------|----------------|
| **测试框架** | pytest + unittest.TestCase | pytest + pytest-mock | pytest + 真实环境 |
| **运行环境** | 临时目录 + 完全Mock | 临时目录 + 部分真实依赖 | 独立测试目录 + 真实环境 |
| **测试替身** | unittest.mock（完全Mock） | unittest.mock + pytest-mock（部分Mock） | monkeypatch（最小Mock） |
| **DSL设计** | 简化ConfigDict + Fixture | 完整ConfigDict + Fixture | 真实配置文件 |
| **数据构造** | Fixture工厂（最小数据集） | Fixture工厂 + 参数化（中等数据集） | 真实数据集文件 |
| **夹具设计** | function作用域（完全隔离） | function/class作用域（部分共享） | class/session作用域（共享环境） |
| **匹配器设计** | 标准断言 + 简单匹配器 | 标准断言 + 复杂匹配器 | 标准断言 + 文件验证匹配器 |
| **并行执行** | pytest-xdist（进程级并行） | 顺序执行（避免资源竞争） | 顺序执行（真实环境） |
| **覆盖率** | 高覆盖率（≥80%） | 中等覆盖率（关键路径） | 低覆盖率（场景验证） |
| **执行速度** | 快速（毫秒级） | 中等（秒级到分钟级） | 慢速（分钟级到小时级） |

#### 5.9 技术方案实施建议

1. **渐进式实施**：从单元测试层开始，逐步扩展到集成测试层和系统测试层
2. **工具链统一**：统一使用pytest作为测试框架，保持一致性
3. **Mock策略优化**：根据测试层级选择合适的Mock策略，平衡真实性和隔离性
4. **Fixture复用**：设计可复用的Fixture，减少代码重复
5. **参数化测试**：使用pytest参数化减少重复测试代码
6. **持续优化**：根据测试执行情况持续优化技术方案

以上技术方案基于AISBench的实际测试代码和配置，针对不同测试层级进行了优化设计。
```

已补充关键测试技术方案，包含：

1. **测试工程设计**：测试框架选型、测试组织结构、测试发现与执行
2. **运行环境**：测试环境隔离、Python环境管理
3. **测试替身设计**：Mock框架选型、Mock策略设计、异步Mock设计
4. **DSL设计**：测试配置DSL、测试数据DSL
5. **数据构造设计**：测试数据生成策略、共享内存数据构造
6. **夹具设计**：Fixture作用域设计、Fixture组合设计
7. **匹配器设计**：断言匹配器选型、Mock验证匹配器

每个技术方案都包含：
- 备选方案对比表（优点、缺点、适用场景）
- 最终方案选择及理由
- 分层映射（UT、ST、E2E）
- 具体实现方式和代码示例

最后提供了技术方案分层映射总结表，便于查阅和对比。